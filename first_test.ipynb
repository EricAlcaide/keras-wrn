{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" First tests with WRN - 10-2. \"\"\"\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "import wrn_high as wrn\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=5,\n",
    "                             width_shift_range=0.125,\n",
    "                             height_shift_range=0.125,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"reflect\")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(x):\n",
    "    if x < 45:\n",
    "        return 0.125\n",
    "    elif x < 85:\n",
    "        return 0.125*0.2\n",
    "    elif x < 105:\n",
    "        return 0.125*0.2*0.2\n",
    "    elif x < 125:\n",
    "        return 0.125*0.2*0.2*0.2\n",
    "    else:\n",
    "        return 0.125*0.2*0.2*0.2*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(act):# SWISH - 125\n",
    "    init_shape = (3, 32, 32) if K.image_dim_ordering() == 'th' else (32, 32, 3)\n",
    "    # For WRN-16-8 put N = 2, k = 8\n",
    "    # For WRN-28-10 put N = 4, k = 10\n",
    "    # For WRN-40-4 put N = 6, k = 4\n",
    "    model = wrn.build_model(init_shape, num_classes, 10, 2)\n",
    "\n",
    "    print(\"Model Created\")\n",
    "    batch_size  = 128\n",
    "    epochs = 125\n",
    "\n",
    "    opt = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    lr_1 = keras.callbacks.LearningRateScheduler(schedule)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    print(\"Finished compiling\")\n",
    "\n",
    "    ####################\n",
    "    # Network training #\n",
    "    ####################\n",
    "\n",
    "    print(\"Gonna fit the model\")\n",
    "    his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test), callbacks=[lr_1])\n",
    "#     print(his.history)\n",
    "    return his.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 1/125\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 1.4636 - acc: 0.4623 - val_loss: 1.3533 - val_acc: 0.5576\n",
      "Epoch 2/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 1.0228 - acc: 0.6376 - val_loss: 1.0025 - val_acc: 0.6565\n",
      "Epoch 3/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.8504 - acc: 0.7041 - val_loss: 0.8529 - val_acc: 0.7124\n",
      "Epoch 4/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.7550 - acc: 0.7360 - val_loss: 1.2492 - val_acc: 0.6346\n",
      "Epoch 5/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.6852 - acc: 0.7618 - val_loss: 0.6488 - val_acc: 0.7781\n",
      "Epoch 6/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.6305 - acc: 0.7806 - val_loss: 0.8291 - val_acc: 0.7328\n",
      "Epoch 7/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5941 - acc: 0.7931 - val_loss: 0.6204 - val_acc: 0.7932\n",
      "Epoch 8/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5595 - acc: 0.8059 - val_loss: 0.6695 - val_acc: 0.7854\n",
      "Epoch 9/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5324 - acc: 0.8153 - val_loss: 0.8586 - val_acc: 0.7269\n",
      "Epoch 10/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5191 - acc: 0.8203 - val_loss: 0.6163 - val_acc: 0.7984\n",
      "Epoch 11/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4943 - acc: 0.8279 - val_loss: 0.8060 - val_acc: 0.7529\n",
      "Epoch 12/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4762 - acc: 0.8369 - val_loss: 0.5885 - val_acc: 0.8093\n",
      "Epoch 13/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4577 - acc: 0.8407 - val_loss: 0.7889 - val_acc: 0.7543\n",
      "Epoch 14/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4435 - acc: 0.8454 - val_loss: 0.6197 - val_acc: 0.8034\n",
      "Epoch 15/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4282 - acc: 0.8531 - val_loss: 0.4826 - val_acc: 0.8425\n",
      "Epoch 16/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4169 - acc: 0.8567 - val_loss: 0.5217 - val_acc: 0.8289\n",
      "Epoch 17/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4097 - acc: 0.8575 - val_loss: 0.5242 - val_acc: 0.8333\n",
      "Epoch 18/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3989 - acc: 0.8616 - val_loss: 0.5877 - val_acc: 0.8154\n",
      "Epoch 19/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3918 - acc: 0.8639 - val_loss: 0.4901 - val_acc: 0.8437\n",
      "Epoch 20/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3785 - acc: 0.8677 - val_loss: 0.5041 - val_acc: 0.8377\n",
      "Epoch 21/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3709 - acc: 0.8709 - val_loss: 0.4670 - val_acc: 0.8433\n",
      "Epoch 22/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3687 - acc: 0.8728 - val_loss: 0.6799 - val_acc: 0.8049\n",
      "Epoch 23/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3549 - acc: 0.8769 - val_loss: 0.4799 - val_acc: 0.8464\n",
      "Epoch 24/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3521 - acc: 0.8774 - val_loss: 0.5041 - val_acc: 0.8352\n",
      "Epoch 25/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3397 - acc: 0.8841 - val_loss: 0.5220 - val_acc: 0.8340\n",
      "Epoch 26/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3376 - acc: 0.8822 - val_loss: 0.4244 - val_acc: 0.8592\n",
      "Epoch 27/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3290 - acc: 0.8865 - val_loss: 0.4783 - val_acc: 0.8501\n",
      "Epoch 28/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3273 - acc: 0.8870 - val_loss: 0.4595 - val_acc: 0.8510\n",
      "Epoch 29/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3233 - acc: 0.8872 - val_loss: 0.5359 - val_acc: 0.8393\n",
      "Epoch 30/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3166 - acc: 0.8897 - val_loss: 0.5665 - val_acc: 0.8237\n",
      "Epoch 31/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3074 - acc: 0.8949 - val_loss: 0.6254 - val_acc: 0.8147\n",
      "Epoch 32/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3061 - acc: 0.8932 - val_loss: 0.4300 - val_acc: 0.8640\n",
      "Epoch 33/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3018 - acc: 0.8947 - val_loss: 0.5066 - val_acc: 0.8457\n",
      "Epoch 34/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2937 - acc: 0.8979 - val_loss: 0.4071 - val_acc: 0.8706\n",
      "Epoch 35/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2930 - acc: 0.8974 - val_loss: 0.8463 - val_acc: 0.7880\n",
      "Epoch 36/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2865 - acc: 0.8997 - val_loss: 0.4297 - val_acc: 0.8593\n",
      "Epoch 37/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2873 - acc: 0.8987 - val_loss: 0.6219 - val_acc: 0.8270\n",
      "Epoch 38/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2828 - acc: 0.9009 - val_loss: 0.4422 - val_acc: 0.8627\n",
      "Epoch 39/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2780 - acc: 0.9050 - val_loss: 0.4516 - val_acc: 0.8592\n",
      "Epoch 40/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2719 - acc: 0.9057 - val_loss: 0.5127 - val_acc: 0.8479\n",
      "Epoch 41/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2707 - acc: 0.9046 - val_loss: 0.4673 - val_acc: 0.8597\n",
      "Epoch 42/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2702 - acc: 0.9067 - val_loss: 0.4356 - val_acc: 0.8649\n",
      "Epoch 43/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2665 - acc: 0.9074 - val_loss: 0.4206 - val_acc: 0.8663\n",
      "Epoch 44/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2547 - acc: 0.9099 - val_loss: 0.3700 - val_acc: 0.8807\n",
      "Epoch 45/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2588 - acc: 0.9110 - val_loss: 0.4898 - val_acc: 0.8555\n",
      "Epoch 46/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2096 - acc: 0.9263 - val_loss: 0.3115 - val_acc: 0.8966\n",
      "Epoch 47/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1914 - acc: 0.9327 - val_loss: 0.3179 - val_acc: 0.8995\n",
      "Epoch 48/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1849 - acc: 0.9365 - val_loss: 0.3124 - val_acc: 0.8990\n",
      "Epoch 49/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1807 - acc: 0.9381 - val_loss: 0.3198 - val_acc: 0.8980\n",
      "Epoch 50/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1812 - acc: 0.9365 - val_loss: 0.3157 - val_acc: 0.8999\n",
      "Epoch 51/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1786 - acc: 0.9376 - val_loss: 0.3241 - val_acc: 0.8971\n",
      "Epoch 52/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1758 - acc: 0.9379 - val_loss: 0.3154 - val_acc: 0.9000\n",
      "Epoch 53/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1761 - acc: 0.9392 - val_loss: 0.3305 - val_acc: 0.8987\n",
      "Epoch 54/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1706 - acc: 0.9406 - val_loss: 0.3328 - val_acc: 0.8958\n",
      "Epoch 55/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1732 - acc: 0.9398 - val_loss: 0.3408 - val_acc: 0.8964\n",
      "Epoch 56/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1710 - acc: 0.9413 - val_loss: 0.3358 - val_acc: 0.8975\n",
      "Epoch 57/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1669 - acc: 0.9420 - val_loss: 0.3232 - val_acc: 0.9020\n",
      "Epoch 58/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1693 - acc: 0.9408 - val_loss: 0.3227 - val_acc: 0.8993\n",
      "Epoch 59/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1693 - acc: 0.9414 - val_loss: 0.3396 - val_acc: 0.8962\n",
      "Epoch 60/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1655 - acc: 0.9418 - val_loss: 0.3281 - val_acc: 0.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1676 - acc: 0.9411 - val_loss: 0.3424 - val_acc: 0.8949\n",
      "Epoch 62/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1633 - acc: 0.9428 - val_loss: 0.3396 - val_acc: 0.8932\n",
      "Epoch 63/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1606 - acc: 0.9443 - val_loss: 0.3320 - val_acc: 0.9006\n",
      "Epoch 64/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1605 - acc: 0.9436 - val_loss: 0.3330 - val_acc: 0.9003\n",
      "Epoch 65/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1602 - acc: 0.9439 - val_loss: 0.3335 - val_acc: 0.9003\n",
      "Epoch 66/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1644 - acc: 0.9426 - val_loss: 0.3392 - val_acc: 0.8987\n",
      "Epoch 67/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1578 - acc: 0.9447 - val_loss: 0.3306 - val_acc: 0.8999\n",
      "Epoch 68/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1602 - acc: 0.9429 - val_loss: 0.3422 - val_acc: 0.9002\n",
      "Epoch 69/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1553 - acc: 0.9452 - val_loss: 0.3415 - val_acc: 0.9007\n",
      "Epoch 70/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1573 - acc: 0.9436 - val_loss: 0.3886 - val_acc: 0.8917\n",
      "Epoch 71/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1556 - acc: 0.9448 - val_loss: 0.3350 - val_acc: 0.9017\n",
      "Epoch 72/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1543 - acc: 0.9456 - val_loss: 0.3278 - val_acc: 0.8994\n",
      "Epoch 73/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1557 - acc: 0.9443 - val_loss: 0.3446 - val_acc: 0.8981\n",
      "Epoch 74/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1540 - acc: 0.9468 - val_loss: 0.3426 - val_acc: 0.8966\n",
      "Epoch 75/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1511 - acc: 0.9475 - val_loss: 0.3596 - val_acc: 0.8998\n",
      "Epoch 76/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1525 - acc: 0.9460 - val_loss: 0.3558 - val_acc: 0.8948\n",
      "Epoch 77/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1516 - acc: 0.9466 - val_loss: 0.3450 - val_acc: 0.8997\n",
      "Epoch 78/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1514 - acc: 0.9459 - val_loss: 0.3393 - val_acc: 0.9013\n",
      "Epoch 79/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1483 - acc: 0.9481 - val_loss: 0.3506 - val_acc: 0.8994\n",
      "Epoch 80/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1503 - acc: 0.9480 - val_loss: 0.3473 - val_acc: 0.8990\n",
      "Epoch 81/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1515 - acc: 0.9472 - val_loss: 0.3517 - val_acc: 0.8978\n",
      "Epoch 82/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1473 - acc: 0.9479 - val_loss: 0.3392 - val_acc: 0.8989\n",
      "Epoch 83/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1448 - acc: 0.9493 - val_loss: 0.3340 - val_acc: 0.8996\n",
      "Epoch 84/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1472 - acc: 0.9477 - val_loss: 0.3453 - val_acc: 0.8998\n",
      "Epoch 85/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1492 - acc: 0.9473 - val_loss: 0.3512 - val_acc: 0.9008\n",
      "Epoch 86/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1392 - acc: 0.9507 - val_loss: 0.3288 - val_acc: 0.9038\n",
      "Epoch 87/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1315 - acc: 0.9539 - val_loss: 0.3271 - val_acc: 0.9049\n",
      "Epoch 88/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1311 - acc: 0.9541 - val_loss: 0.3233 - val_acc: 0.9042\n",
      "Epoch 89/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1271 - acc: 0.9543 - val_loss: 0.3257 - val_acc: 0.9059\n",
      "Epoch 90/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1225 - acc: 0.9575 - val_loss: 0.3227 - val_acc: 0.9043\n",
      "Epoch 91/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1249 - acc: 0.9571 - val_loss: 0.3264 - val_acc: 0.9059\n",
      "Epoch 92/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1255 - acc: 0.9560 - val_loss: 0.3272 - val_acc: 0.9048\n",
      "Epoch 93/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1274 - acc: 0.9548 - val_loss: 0.3300 - val_acc: 0.9047\n",
      "Epoch 94/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1261 - acc: 0.9559 - val_loss: 0.3291 - val_acc: 0.9058\n",
      "Epoch 95/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1242 - acc: 0.9569 - val_loss: 0.3309 - val_acc: 0.9043\n",
      "Epoch 96/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1234 - acc: 0.9569 - val_loss: 0.3361 - val_acc: 0.9045\n",
      "Epoch 97/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1298 - acc: 0.9546 - val_loss: 0.3281 - val_acc: 0.9061\n",
      "Epoch 98/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1272 - acc: 0.9546 - val_loss: 0.3384 - val_acc: 0.9037\n",
      "Epoch 99/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1235 - acc: 0.9569 - val_loss: 0.3337 - val_acc: 0.9044\n",
      "Epoch 100/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1251 - acc: 0.9558 - val_loss: 0.3340 - val_acc: 0.9062\n",
      "Epoch 101/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1261 - acc: 0.9560 - val_loss: 0.3340 - val_acc: 0.9044\n",
      "Epoch 102/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1240 - acc: 0.9576 - val_loss: 0.3324 - val_acc: 0.9049\n",
      "Epoch 103/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1232 - acc: 0.9567 - val_loss: 0.3337 - val_acc: 0.9056\n",
      "Epoch 104/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1229 - acc: 0.9566 - val_loss: 0.3354 - val_acc: 0.9050\n",
      "Epoch 105/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1259 - acc: 0.9551 - val_loss: 0.3349 - val_acc: 0.9050\n",
      "Epoch 106/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1208 - acc: 0.9576 - val_loss: 0.3335 - val_acc: 0.9058\n",
      "Epoch 107/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1219 - acc: 0.9575 - val_loss: 0.3343 - val_acc: 0.9052\n",
      "Epoch 108/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1207 - acc: 0.9581 - val_loss: 0.3316 - val_acc: 0.9055\n",
      "Epoch 109/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1189 - acc: 0.9582 - val_loss: 0.3331 - val_acc: 0.9045\n",
      "Epoch 110/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1225 - acc: 0.9575 - val_loss: 0.3328 - val_acc: 0.9049\n",
      "Epoch 111/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1218 - acc: 0.9567 - val_loss: 0.3339 - val_acc: 0.9048\n",
      "Epoch 112/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1218 - acc: 0.9564 - val_loss: 0.3353 - val_acc: 0.9050\n",
      "Epoch 113/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1180 - acc: 0.9587 - val_loss: 0.3351 - val_acc: 0.9050\n",
      "Epoch 114/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1213 - acc: 0.9576 - val_loss: 0.3334 - val_acc: 0.9046\n",
      "Epoch 115/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1226 - acc: 0.9562 - val_loss: 0.3348 - val_acc: 0.9053\n",
      "Epoch 116/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1196 - acc: 0.9577 - val_loss: 0.3349 - val_acc: 0.9054\n",
      "Epoch 117/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1208 - acc: 0.9575 - val_loss: 0.3343 - val_acc: 0.9053\n",
      "Epoch 118/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1198 - acc: 0.9578 - val_loss: 0.3325 - val_acc: 0.9056\n",
      "Epoch 119/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1180 - acc: 0.9585 - val_loss: 0.3331 - val_acc: 0.9051\n",
      "Epoch 120/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1205 - acc: 0.9572 - val_loss: 0.3336 - val_acc: 0.9056\n",
      "Epoch 121/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1195 - acc: 0.9581 - val_loss: 0.3327 - val_acc: 0.9056\n",
      "Epoch 122/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1193 - acc: 0.9580 - val_loss: 0.3332 - val_acc: 0.9050\n",
      "Epoch 123/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1192 - acc: 0.9578 - val_loss: 0.3338 - val_acc: 0.9059\n",
      "Epoch 124/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1206 - acc: 0.9593 - val_loss: 0.3325 - val_acc: 0.9055\n",
      "Epoch 125/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1200 - acc: 0.9585 - val_loss: 0.3344 - val_acc: 0.9054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [0.46216313761321637,\n",
       "  0.63755213342341699,\n",
       "  0.70414260504985415,\n",
       "  0.73594401664446285,\n",
       "  0.761810234161306,\n",
       "  0.7805983317101044,\n",
       "  0.79299005453962146,\n",
       "  0.80596326592261491,\n",
       "  0.81534728905999354,\n",
       "  0.82023981392364453,\n",
       "  0.82789942248341053,\n",
       "  0.836822264960151,\n",
       "  0.84069217199846302,\n",
       "  0.84540423487943839,\n",
       "  0.8530838947323679,\n",
       "  0.85669313446237061,\n",
       "  0.85741498239307323,\n",
       "  0.86166586457516547,\n",
       "  0.86383140838639572,\n",
       "  0.86762111000346187,\n",
       "  0.87088947704215447,\n",
       "  0.87289461020211745,\n",
       "  0.87690487648379856,\n",
       "  0.87738610841847786,\n",
       "  0.88408325310888525,\n",
       "  0.8821984280138625,\n",
       "  0.88652951555983317,\n",
       "  0.88701074747538999,\n",
       "  0.88729146611510767,\n",
       "  0.8897577799548313,\n",
       "  0.894951074732241,\n",
       "  0.89326676287481255,\n",
       "  0.89467035609252332,\n",
       "  0.89783846651241872,\n",
       "  0.89739733720231141,\n",
       "  0.89968318892550236,\n",
       "  0.89878087903124648,\n",
       "  0.90096647419300757,\n",
       "  0.90499679178697467,\n",
       "  0.90565848568520713,\n",
       "  0.90461581649021494,\n",
       "  0.90674125758126101,\n",
       "  0.9074230028491469,\n",
       "  0.90988931661238071,\n",
       "  0.91099759615384612,\n",
       "  0.9263206487025063,\n",
       "  0.93266762913057422,\n",
       "  0.93647738213641618,\n",
       "  0.93814164262419142,\n",
       "  0.93647836538461537,\n",
       "  0.93762042393038192,\n",
       "  0.93784087261482041,\n",
       "  0.93924446583253129,\n",
       "  0.94058790503689449,\n",
       "  0.93984374999999998,\n",
       "  0.941353564566347,\n",
       "  0.94197144688495205,\n",
       "  0.94078525641025645,\n",
       "  0.94137363515760786,\n",
       "  0.94173083096541843,\n",
       "  0.94108573717948718,\n",
       "  0.94275850993590093,\n",
       "  0.94429086538461537,\n",
       "  0.94362154782928565,\n",
       "  0.94387632340699534,\n",
       "  0.94255293549579577,\n",
       "  0.94469842795649517,\n",
       "  0.94295396216220873,\n",
       "  0.94519971124170532,\n",
       "  0.9435555021235833,\n",
       "  0.94481873594494559,\n",
       "  0.94564084055181263,\n",
       "  0.94431745271710277,\n",
       "  0.94683493589743595,\n",
       "  0.94749518306345681,\n",
       "  0.94602181581032752,\n",
       "  0.94654315048431337,\n",
       "  0.94594161056118364,\n",
       "  0.94813701923076921,\n",
       "  0.94797687857443502,\n",
       "  0.94720484438254582,\n",
       "  0.94785657051282046,\n",
       "  0.9493015413875372,\n",
       "  0.94770612770600082,\n",
       "  0.94726499835764866,\n",
       "  0.95067372473532241,\n",
       "  0.95394631410256414,\n",
       "  0.95409842640372067,\n",
       "  0.95426291301918209,\n",
       "  0.95751122870734384,\n",
       "  0.95707131410256407,\n",
       "  0.95602520875388719,\n",
       "  0.95482435031773993,\n",
       "  0.95596727626538636,\n",
       "  0.95684953477086643,\n",
       "  0.9568695861022749,\n",
       "  0.95462383698453346,\n",
       "  0.95462383700365583,\n",
       "  0.95693108974358976,\n",
       "  0.95582691686903776,\n",
       "  0.95602520865818286,\n",
       "  0.95757138272069153,\n",
       "  0.95672922685890582,\n",
       "  0.95663060897435892,\n",
       "  0.95516217082222077,\n",
       "  0.95763153671491674,\n",
       "  0.95751122870734384,\n",
       "  0.95813281998100441,\n",
       "  0.95819297397522962,\n",
       "  0.95745192307692306,\n",
       "  0.95672922680153849,\n",
       "  0.95646676306320288,\n",
       "  0.95869425731780711,\n",
       "  0.9575520833333333,\n",
       "  0.95622591524072087,\n",
       "  0.95765158802720263,\n",
       "  0.95751201923076923,\n",
       "  0.95777189603477553,\n",
       "  0.95855389799794821,\n",
       "  0.95720937702620568,\n",
       "  0.95807291666666672,\n",
       "  0.95805234427090713,\n",
       "  0.95783253205128205,\n",
       "  0.95927665387887406,\n",
       "  0.95849374402284548],\n",
       " 'loss': [1.4637850606751281,\n",
       "  1.022853697287107,\n",
       "  0.85040882458318146,\n",
       "  0.7548379952761467,\n",
       "  0.68522286753567285,\n",
       "  0.63046443923222628,\n",
       "  0.59428436083215375,\n",
       "  0.5594987142609984,\n",
       "  0.53247503826814768,\n",
       "  0.51910470601531,\n",
       "  0.49417498884653871,\n",
       "  0.47637221874011265,\n",
       "  0.4577709803663082,\n",
       "  0.4435638748073486,\n",
       "  0.42815701424941671,\n",
       "  0.41700976465541584,\n",
       "  0.40979637767322408,\n",
       "  0.39876040247414485,\n",
       "  0.39187849402657143,\n",
       "  0.37852329115168498,\n",
       "  0.37092561787009276,\n",
       "  0.36870900242038745,\n",
       "  0.35506887304159473,\n",
       "  0.35211222184021806,\n",
       "  0.33973918193075797,\n",
       "  0.33768626086636161,\n",
       "  0.3289045834621635,\n",
       "  0.32744704040151629,\n",
       "  0.32312447610940159,\n",
       "  0.31660585071476827,\n",
       "  0.30742851367240004,\n",
       "  0.30593002567239247,\n",
       "  0.30186402790049999,\n",
       "  0.29373607787138994,\n",
       "  0.29310486062926133,\n",
       "  0.28641225005098747,\n",
       "  0.28715001026100939,\n",
       "  0.28268345155928581,\n",
       "  0.27792457606611171,\n",
       "  0.27188415323880993,\n",
       "  0.27079175423172219,\n",
       "  0.2700812175826916,\n",
       "  0.26645050435675083,\n",
       "  0.25461124015190983,\n",
       "  0.25880478534560936,\n",
       "  0.20962696421506241,\n",
       "  0.191370237024694,\n",
       "  0.18484975150429289,\n",
       "  0.18073940295265928,\n",
       "  0.18120651701704049,\n",
       "  0.17864463255814275,\n",
       "  0.17586125280465459,\n",
       "  0.17597390114209344,\n",
       "  0.17051122845041472,\n",
       "  0.17315691330302985,\n",
       "  0.17081997420114819,\n",
       "  0.16691586868595457,\n",
       "  0.1693160629329773,\n",
       "  0.16935801832872702,\n",
       "  0.16558522400964634,\n",
       "  0.16762345866897169,\n",
       "  0.16335938376594064,\n",
       "  0.16056662853329609,\n",
       "  0.16057503872772938,\n",
       "  0.16031846337864175,\n",
       "  0.16442252912122085,\n",
       "  0.15784589603022195,\n",
       "  0.16016685286698756,\n",
       "  0.1553648645569202,\n",
       "  0.15735672724325381,\n",
       "  0.15558156916584231,\n",
       "  0.15427047933069682,\n",
       "  0.15570541613944111,\n",
       "  0.15399280480849437,\n",
       "  0.15109629242387274,\n",
       "  0.15250765579822242,\n",
       "  0.15167647013832142,\n",
       "  0.15131359994602692,\n",
       "  0.14834866789289011,\n",
       "  0.15023507141701364,\n",
       "  0.15149130409521899,\n",
       "  0.1472517385123632,\n",
       "  0.14484511455072374,\n",
       "  0.14721934805227696,\n",
       "  0.14927082635727609,\n",
       "  0.13913205794734301,\n",
       "  0.13152427510000192,\n",
       "  0.13110435765306003,\n",
       "  0.12708085832264623,\n",
       "  0.12253825537164814,\n",
       "  0.1248794339501705,\n",
       "  0.12551930856364005,\n",
       "  0.12743092166486367,\n",
       "  0.12603972200632937,\n",
       "  0.12428944492410841,\n",
       "  0.12341557237097649,\n",
       "  0.12979378732668884,\n",
       "  0.12715816088582524,\n",
       "  0.12349592056603004,\n",
       "  0.12513667694509584,\n",
       "  0.12616498180944413,\n",
       "  0.12404200271187893,\n",
       "  0.1232327869640622,\n",
       "  0.12285564391372296,\n",
       "  0.12586565843532693,\n",
       "  0.1207776241623556,\n",
       "  0.12186530962428643,\n",
       "  0.12069485869819169,\n",
       "  0.11897066743721134,\n",
       "  0.12250452128549418,\n",
       "  0.12171072590071917,\n",
       "  0.1216634850070962,\n",
       "  0.1180473185602407,\n",
       "  0.12130041124346928,\n",
       "  0.12257694290542955,\n",
       "  0.11958450064144342,\n",
       "  0.12077165143803144,\n",
       "  0.11983913090946509,\n",
       "  0.11786805634931528,\n",
       "  0.12054318854765932,\n",
       "  0.11949313582900242,\n",
       "  0.11924638967140408,\n",
       "  0.11916041559515855,\n",
       "  0.12048553100708745,\n",
       "  0.12004688821247766],\n",
       " 'val_acc': [0.55759999999999998,\n",
       "  0.65649999999999997,\n",
       "  0.71240000000000003,\n",
       "  0.63460000000000005,\n",
       "  0.77810000000000001,\n",
       "  0.73280000000000001,\n",
       "  0.79320000000000002,\n",
       "  0.78539999999999999,\n",
       "  0.72689999999999999,\n",
       "  0.7984,\n",
       "  0.75290000000000001,\n",
       "  0.80930000000000002,\n",
       "  0.75429999999999997,\n",
       "  0.8034,\n",
       "  0.84250000000000003,\n",
       "  0.82889999999999997,\n",
       "  0.83330000000000004,\n",
       "  0.81540000000000001,\n",
       "  0.84370000000000001,\n",
       "  0.8377,\n",
       "  0.84330000000000005,\n",
       "  0.80489999999999995,\n",
       "  0.84640000000000004,\n",
       "  0.83520000000000005,\n",
       "  0.83399999999999996,\n",
       "  0.85919999999999996,\n",
       "  0.85009999999999997,\n",
       "  0.85099999999999998,\n",
       "  0.83930000000000005,\n",
       "  0.82369999999999999,\n",
       "  0.81469999999999998,\n",
       "  0.86399999999999999,\n",
       "  0.84570000000000001,\n",
       "  0.87060000000000004,\n",
       "  0.78800000000000003,\n",
       "  0.85929999999999995,\n",
       "  0.82699999999999996,\n",
       "  0.86270000000000002,\n",
       "  0.85919999999999996,\n",
       "  0.84789999999999999,\n",
       "  0.85970000000000002,\n",
       "  0.8649,\n",
       "  0.86629999999999996,\n",
       "  0.88070000000000004,\n",
       "  0.85550000000000004,\n",
       "  0.89659999999999995,\n",
       "  0.89949999999999997,\n",
       "  0.89900000000000002,\n",
       "  0.89800000000000002,\n",
       "  0.89990000000000003,\n",
       "  0.89710000000000001,\n",
       "  0.90000000000000002,\n",
       "  0.89870000000000005,\n",
       "  0.89580000000000004,\n",
       "  0.89639999999999997,\n",
       "  0.89749999999999996,\n",
       "  0.90200000000000002,\n",
       "  0.89929999999999999,\n",
       "  0.8962,\n",
       "  0.89990000000000003,\n",
       "  0.89490000000000003,\n",
       "  0.89319999999999999,\n",
       "  0.90059999999999996,\n",
       "  0.90029999999999999,\n",
       "  0.90029999999999999,\n",
       "  0.89870000000000005,\n",
       "  0.89990000000000003,\n",
       "  0.9002,\n",
       "  0.90069999999999995,\n",
       "  0.89170000000000005,\n",
       "  0.90169999999999995,\n",
       "  0.89939999999999998,\n",
       "  0.89810000000000001,\n",
       "  0.89659999999999995,\n",
       "  0.89980000000000004,\n",
       "  0.89480000000000004,\n",
       "  0.89970000000000006,\n",
       "  0.90129999999999999,\n",
       "  0.89939999999999998,\n",
       "  0.89900000000000002,\n",
       "  0.89780000000000004,\n",
       "  0.89890000000000003,\n",
       "  0.89959999999999996,\n",
       "  0.89980000000000004,\n",
       "  0.90080000000000005,\n",
       "  0.90380000000000005,\n",
       "  0.90490000000000004,\n",
       "  0.9042,\n",
       "  0.90590000000000004,\n",
       "  0.90429999999999999,\n",
       "  0.90590000000000004,\n",
       "  0.90480000000000005,\n",
       "  0.90469999999999995,\n",
       "  0.90580000000000005,\n",
       "  0.90429999999999999,\n",
       "  0.90449999999999997,\n",
       "  0.90610000000000002,\n",
       "  0.90369999999999995,\n",
       "  0.90439999999999998,\n",
       "  0.90620000000000001,\n",
       "  0.90439999999999998,\n",
       "  0.90490000000000004,\n",
       "  0.90559999999999996,\n",
       "  0.90500000000000003,\n",
       "  0.90500000000000003,\n",
       "  0.90580000000000005,\n",
       "  0.9052,\n",
       "  0.90549999999999997,\n",
       "  0.90449999999999997,\n",
       "  0.90490000000000004,\n",
       "  0.90480000000000005,\n",
       "  0.90500000000000003,\n",
       "  0.90500000000000003,\n",
       "  0.90459999999999996,\n",
       "  0.90529999999999999,\n",
       "  0.90539999999999998,\n",
       "  0.90529999999999999,\n",
       "  0.90559999999999996,\n",
       "  0.90510000000000002,\n",
       "  0.90559999999999996,\n",
       "  0.90559999999999996,\n",
       "  0.90500000000000003,\n",
       "  0.90590000000000004,\n",
       "  0.90549999999999997,\n",
       "  0.90539999999999998],\n",
       " 'val_loss': [1.353323163986206,\n",
       "  1.0025371114730834,\n",
       "  0.85287384414672851,\n",
       "  1.2491707580566407,\n",
       "  0.64875788822174074,\n",
       "  0.82910852098464971,\n",
       "  0.62035962400436406,\n",
       "  0.66949315161705014,\n",
       "  0.85864888162612918,\n",
       "  0.616349549806118,\n",
       "  0.80599965224266057,\n",
       "  0.5884666858196258,\n",
       "  0.7888578023910523,\n",
       "  0.61974483306407924,\n",
       "  0.48262069468498231,\n",
       "  0.52170121026039129,\n",
       "  0.52422588205337528,\n",
       "  0.58774777512550358,\n",
       "  0.49010205001831053,\n",
       "  0.50408467121124267,\n",
       "  0.46701718142032622,\n",
       "  0.67988276298046113,\n",
       "  0.47992829566001893,\n",
       "  0.5041404960393906,\n",
       "  0.52200938162803645,\n",
       "  0.42438960990905761,\n",
       "  0.47829693975448606,\n",
       "  0.45946596815586088,\n",
       "  0.53589100656509403,\n",
       "  0.56646907691955561,\n",
       "  0.6253511852264404,\n",
       "  0.43003951573371885,\n",
       "  0.50656242337226864,\n",
       "  0.40708639755249021,\n",
       "  0.84626994872093197,\n",
       "  0.4296520199418068,\n",
       "  0.62192248890399937,\n",
       "  0.44219406123161314,\n",
       "  0.45161027297973633,\n",
       "  0.51273603758811948,\n",
       "  0.46728022584915163,\n",
       "  0.43564885373115542,\n",
       "  0.42056695747375489,\n",
       "  0.36998703331947325,\n",
       "  0.48977787570953368,\n",
       "  0.31154110217094422,\n",
       "  0.31785920433998111,\n",
       "  0.31240086607933043,\n",
       "  0.3197853605270386,\n",
       "  0.31571834406852722,\n",
       "  0.32406212854385374,\n",
       "  0.31535026581287384,\n",
       "  0.33046883597373961,\n",
       "  0.33277676885128021,\n",
       "  0.34078011355400084,\n",
       "  0.33582431688308717,\n",
       "  0.32317621958255766,\n",
       "  0.32274720501899717,\n",
       "  0.33955457658767702,\n",
       "  0.32808970525264741,\n",
       "  0.34242585325241087,\n",
       "  0.33955400536060332,\n",
       "  0.33196146869659426,\n",
       "  0.33302259116172789,\n",
       "  0.3334626545906067,\n",
       "  0.33918341860771178,\n",
       "  0.33055404357910156,\n",
       "  0.34215825214385986,\n",
       "  0.341463890004158,\n",
       "  0.38860306124687194,\n",
       "  0.33500632696151733,\n",
       "  0.32784482145309446,\n",
       "  0.34459880020618439,\n",
       "  0.3426031925201416,\n",
       "  0.35955334429740904,\n",
       "  0.35584086959362032,\n",
       "  0.34499460163116458,\n",
       "  0.33933509571552278,\n",
       "  0.35058630285263059,\n",
       "  0.3473234972476959,\n",
       "  0.351678400850296,\n",
       "  0.3391634175300598,\n",
       "  0.3339948905944824,\n",
       "  0.34530498552322386,\n",
       "  0.35118101353645326,\n",
       "  0.32875078520774842,\n",
       "  0.32710770835876463,\n",
       "  0.32326627120971679,\n",
       "  0.32573785974979402,\n",
       "  0.3226978904724121,\n",
       "  0.32640173878669737,\n",
       "  0.32715398092269898,\n",
       "  0.32998115315437315,\n",
       "  0.32914018716812132,\n",
       "  0.33085027027130126,\n",
       "  0.33610503754615784,\n",
       "  0.3280963866472244,\n",
       "  0.33836231398582456,\n",
       "  0.33367895352840421,\n",
       "  0.33398548111915588,\n",
       "  0.33399665021896363,\n",
       "  0.33238976860046388,\n",
       "  0.33368272321224213,\n",
       "  0.33536807582378386,\n",
       "  0.33490030291080475,\n",
       "  0.33350346159934996,\n",
       "  0.33427589402198793,\n",
       "  0.33157565414905549,\n",
       "  0.33311553215980527,\n",
       "  0.332827321100235,\n",
       "  0.33392744333744051,\n",
       "  0.33527452092170718,\n",
       "  0.33514246401786807,\n",
       "  0.33335576860904692,\n",
       "  0.33481943032741546,\n",
       "  0.33485469567775727,\n",
       "  0.33427840008735654,\n",
       "  0.33250251610279086,\n",
       "  0.33306731452941896,\n",
       "  0.33361223428249359,\n",
       "  0.33270741171836854,\n",
       "  0.33319993264675141,\n",
       "  0.33376401503086089,\n",
       "  0.33247149395942688,\n",
       "  0.334407484126091]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 1/125\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 1.4812 - acc: 0.4551 - val_loss: 1.6290 - val_acc: 0.4853\n",
      "Epoch 2/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 1.0406 - acc: 0.6292 - val_loss: 1.0975 - val_acc: 0.6407\n",
      "Epoch 3/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.8597 - acc: 0.6945 - val_loss: 0.8614 - val_acc: 0.7006\n",
      "Epoch 4/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.7603 - acc: 0.7325 - val_loss: 1.1223 - val_acc: 0.6097\n",
      "Epoch 5/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.6915 - acc: 0.7601 - val_loss: 1.2396 - val_acc: 0.6442\n",
      "Epoch 6/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.6447 - acc: 0.7758 - val_loss: 0.8798 - val_acc: 0.7202\n",
      "Epoch 7/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5972 - acc: 0.7934 - val_loss: 0.8105 - val_acc: 0.7370\n",
      "Epoch 8/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5708 - acc: 0.8006 - val_loss: 0.6330 - val_acc: 0.7879\n",
      "Epoch 9/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5383 - acc: 0.8153 - val_loss: 0.5286 - val_acc: 0.8173\n",
      "Epoch 10/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5156 - acc: 0.8218 - val_loss: 0.9276 - val_acc: 0.7294\n",
      "Epoch 11/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5100 - acc: 0.8230 - val_loss: 0.7743 - val_acc: 0.7694\n",
      "Epoch 12/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4827 - acc: 0.8329 - val_loss: 0.6828 - val_acc: 0.7873\n",
      "Epoch 13/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4651 - acc: 0.8395 - val_loss: 0.6341 - val_acc: 0.7905\n",
      "Epoch 14/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4494 - acc: 0.8430 - val_loss: 0.6020 - val_acc: 0.8132\n",
      "Epoch 15/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4379 - acc: 0.8480 - val_loss: 0.7650 - val_acc: 0.7725\n",
      "Epoch 16/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4289 - acc: 0.8515 - val_loss: 0.7475 - val_acc: 0.7679\n",
      "Epoch 17/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4127 - acc: 0.8567 - val_loss: 0.5240 - val_acc: 0.8258\n",
      "Epoch 18/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4069 - acc: 0.8575 - val_loss: 0.5361 - val_acc: 0.8278\n",
      "Epoch 19/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3967 - acc: 0.8624 - val_loss: 0.5815 - val_acc: 0.8214\n",
      "Epoch 20/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3867 - acc: 0.8639 - val_loss: 0.4864 - val_acc: 0.8331\n",
      "Epoch 21/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3844 - acc: 0.8650 - val_loss: 0.5604 - val_acc: 0.8314\n",
      "Epoch 22/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3661 - acc: 0.8711 - val_loss: 0.4894 - val_acc: 0.8339\n",
      "Epoch 23/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3637 - acc: 0.8722 - val_loss: 0.6215 - val_acc: 0.8130\n",
      "Epoch 24/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3587 - acc: 0.8738 - val_loss: 0.5624 - val_acc: 0.8284\n",
      "Epoch 25/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3460 - acc: 0.8785 - val_loss: 0.4197 - val_acc: 0.8640\n",
      "Epoch 26/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3430 - acc: 0.8818 - val_loss: 0.4923 - val_acc: 0.8517\n",
      "Epoch 27/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3377 - acc: 0.8823 - val_loss: 0.5082 - val_acc: 0.8428\n",
      "Epoch 28/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3282 - acc: 0.8863 - val_loss: 0.5683 - val_acc: 0.8328\n",
      "Epoch 29/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3272 - acc: 0.8847 - val_loss: 0.4319 - val_acc: 0.8615\n",
      "Epoch 30/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3234 - acc: 0.8889 - val_loss: 0.4011 - val_acc: 0.8716\n",
      "Epoch 31/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3111 - acc: 0.8914 - val_loss: 0.5128 - val_acc: 0.8467\n",
      "Epoch 32/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3076 - acc: 0.8927 - val_loss: 0.6458 - val_acc: 0.8153\n",
      "Epoch 33/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3105 - acc: 0.8908 - val_loss: 0.4952 - val_acc: 0.8515\n",
      "Epoch 34/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3042 - acc: 0.8948 - val_loss: 0.5307 - val_acc: 0.8467\n",
      "Epoch 35/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2924 - acc: 0.8981 - val_loss: 0.4523 - val_acc: 0.8560\n",
      "Epoch 36/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2894 - acc: 0.9002 - val_loss: 0.4656 - val_acc: 0.8581\n",
      "Epoch 37/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2898 - acc: 0.9004 - val_loss: 0.4934 - val_acc: 0.8523\n",
      "Epoch 38/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2832 - acc: 0.9014 - val_loss: 0.4768 - val_acc: 0.8539\n",
      "Epoch 39/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2796 - acc: 0.9015 - val_loss: 0.6547 - val_acc: 0.8126\n",
      "Epoch 40/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2809 - acc: 0.9022 - val_loss: 0.4037 - val_acc: 0.8713\n",
      "Epoch 41/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2750 - acc: 0.9034 - val_loss: 0.4243 - val_acc: 0.8664\n",
      "Epoch 42/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2719 - acc: 0.9054 - val_loss: 0.5326 - val_acc: 0.8442\n",
      "Epoch 43/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2713 - acc: 0.9059 - val_loss: 0.4361 - val_acc: 0.8580\n",
      "Epoch 44/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2721 - acc: 0.9053 - val_loss: 0.6206 - val_acc: 0.8190\n",
      "Epoch 45/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2592 - acc: 0.9088 - val_loss: 0.4519 - val_acc: 0.8566\n",
      "Epoch 46/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2140 - acc: 0.9262 - val_loss: 0.3231 - val_acc: 0.8944\n",
      "Epoch 47/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1964 - acc: 0.9323 - val_loss: 0.3303 - val_acc: 0.8904\n",
      "Epoch 48/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1914 - acc: 0.9335 - val_loss: 0.3410 - val_acc: 0.8905\n",
      "Epoch 49/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1862 - acc: 0.9347 - val_loss: 0.3311 - val_acc: 0.8945\n",
      "Epoch 50/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1829 - acc: 0.9357 - val_loss: 0.3337 - val_acc: 0.8974\n",
      "Epoch 51/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1800 - acc: 0.9377 - val_loss: 0.3455 - val_acc: 0.8927\n",
      "Epoch 52/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1775 - acc: 0.9384 - val_loss: 0.3383 - val_acc: 0.8948\n",
      "Epoch 53/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1805 - acc: 0.9365 - val_loss: 0.3369 - val_acc: 0.8965\n",
      "Epoch 54/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1760 - acc: 0.9374 - val_loss: 0.3408 - val_acc: 0.8982\n",
      "Epoch 55/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1746 - acc: 0.9379 - val_loss: 0.3395 - val_acc: 0.8941\n",
      "Epoch 56/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1702 - acc: 0.9405 - val_loss: 0.3388 - val_acc: 0.8951\n",
      "Epoch 57/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1728 - acc: 0.9392 - val_loss: 0.3297 - val_acc: 0.8965\n",
      "Epoch 58/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1731 - acc: 0.9393 - val_loss: 0.3529 - val_acc: 0.8911\n",
      "Epoch 59/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1661 - acc: 0.9424 - val_loss: 0.3518 - val_acc: 0.8942\n",
      "Epoch 60/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1696 - acc: 0.9409 - val_loss: 0.3523 - val_acc: 0.8931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1675 - acc: 0.9411 - val_loss: 0.3609 - val_acc: 0.8927\n",
      "Epoch 62/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1629 - acc: 0.9416 - val_loss: 0.3461 - val_acc: 0.8896\n",
      "Epoch 63/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1661 - acc: 0.9417 - val_loss: 0.3618 - val_acc: 0.8902\n",
      "Epoch 64/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1638 - acc: 0.9429 - val_loss: 0.3723 - val_acc: 0.8899\n",
      "Epoch 65/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1620 - acc: 0.9430 - val_loss: 0.3712 - val_acc: 0.8901\n",
      "Epoch 66/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1634 - acc: 0.9423 - val_loss: 0.3391 - val_acc: 0.8973\n",
      "Epoch 67/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1619 - acc: 0.9420 - val_loss: 0.3369 - val_acc: 0.8946\n",
      "Epoch 68/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1576 - acc: 0.9447 - val_loss: 0.3551 - val_acc: 0.8919\n",
      "Epoch 69/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1567 - acc: 0.9439 - val_loss: 0.3647 - val_acc: 0.8932\n",
      "Epoch 70/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1591 - acc: 0.9429 - val_loss: 0.3682 - val_acc: 0.8906\n",
      "Epoch 71/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1565 - acc: 0.9444 - val_loss: 0.3612 - val_acc: 0.8917\n",
      "Epoch 72/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1577 - acc: 0.9451 - val_loss: 0.3401 - val_acc: 0.8961\n",
      "Epoch 73/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1545 - acc: 0.9454 - val_loss: 0.3501 - val_acc: 0.8938\n",
      "Epoch 74/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1586 - acc: 0.9446 - val_loss: 0.3916 - val_acc: 0.8864\n",
      "Epoch 75/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1533 - acc: 0.9447 - val_loss: 0.3526 - val_acc: 0.8972\n",
      "Epoch 76/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1548 - acc: 0.9453 - val_loss: 0.3593 - val_acc: 0.8903\n",
      "Epoch 77/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1537 - acc: 0.9454 - val_loss: 0.3556 - val_acc: 0.8933\n",
      "Epoch 78/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1536 - acc: 0.9454 - val_loss: 0.3657 - val_acc: 0.8952\n",
      "Epoch 79/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1484 - acc: 0.9469 - val_loss: 0.3568 - val_acc: 0.8952\n",
      "Epoch 80/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1538 - acc: 0.9460 - val_loss: 0.3745 - val_acc: 0.8877\n",
      "Epoch 81/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1497 - acc: 0.9464 - val_loss: 0.3733 - val_acc: 0.8891\n",
      "Epoch 82/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1502 - acc: 0.9466 - val_loss: 0.3588 - val_acc: 0.8950\n",
      "Epoch 83/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1483 - acc: 0.9473 - val_loss: 0.3662 - val_acc: 0.8924\n",
      "Epoch 84/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1519 - acc: 0.9463 - val_loss: 0.3660 - val_acc: 0.8937\n",
      "Epoch 85/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1460 - acc: 0.9486 - val_loss: 0.3696 - val_acc: 0.8948\n",
      "Epoch 86/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1345 - acc: 0.9526 - val_loss: 0.3505 - val_acc: 0.8949\n",
      "Epoch 87/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1307 - acc: 0.9538 - val_loss: 0.3440 - val_acc: 0.8987\n",
      "Epoch 88/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1314 - acc: 0.9542 - val_loss: 0.3410 - val_acc: 0.9005\n",
      "Epoch 89/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1306 - acc: 0.9540 - val_loss: 0.3407 - val_acc: 0.8986\n",
      "Epoch 90/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1284 - acc: 0.9559 - val_loss: 0.3412 - val_acc: 0.8986\n",
      "Epoch 91/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1286 - acc: 0.9553 - val_loss: 0.3426 - val_acc: 0.8991\n",
      "Epoch 92/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1264 - acc: 0.9548 - val_loss: 0.3488 - val_acc: 0.8987\n",
      "Epoch 93/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1306 - acc: 0.9531 - val_loss: 0.3432 - val_acc: 0.8999\n",
      "Epoch 94/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1289 - acc: 0.9550 - val_loss: 0.3414 - val_acc: 0.8996\n",
      "Epoch 95/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1284 - acc: 0.9545 - val_loss: 0.3464 - val_acc: 0.8989\n",
      "Epoch 96/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1286 - acc: 0.9547 - val_loss: 0.3480 - val_acc: 0.8990\n",
      "Epoch 97/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1270 - acc: 0.9562 - val_loss: 0.3509 - val_acc: 0.8980\n",
      "Epoch 98/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1291 - acc: 0.9540 - val_loss: 0.3442 - val_acc: 0.8997\n",
      "Epoch 99/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1242 - acc: 0.9567 - val_loss: 0.3480 - val_acc: 0.8989\n",
      "Epoch 100/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1278 - acc: 0.9543 - val_loss: 0.3494 - val_acc: 0.8992\n",
      "Epoch 101/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1258 - acc: 0.9566 - val_loss: 0.3508 - val_acc: 0.8981\n",
      "Epoch 102/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1260 - acc: 0.9565 - val_loss: 0.3498 - val_acc: 0.8994\n",
      "Epoch 103/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1255 - acc: 0.9555 - val_loss: 0.3499 - val_acc: 0.8986\n",
      "Epoch 104/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1260 - acc: 0.9537 - val_loss: 0.3533 - val_acc: 0.8961\n",
      "Epoch 105/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1233 - acc: 0.9568 - val_loss: 0.3520 - val_acc: 0.8974\n",
      "Epoch 106/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1223 - acc: 0.9562 - val_loss: 0.3497 - val_acc: 0.8995\n",
      "Epoch 107/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1205 - acc: 0.9582 - val_loss: 0.3492 - val_acc: 0.8991\n",
      "Epoch 108/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1193 - acc: 0.9586 - val_loss: 0.3517 - val_acc: 0.8989\n",
      "Epoch 109/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1236 - acc: 0.9575 - val_loss: 0.3505 - val_acc: 0.9000\n",
      "Epoch 110/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1225 - acc: 0.9565 - val_loss: 0.3505 - val_acc: 0.8984\n",
      "Epoch 111/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1274 - acc: 0.9554 - val_loss: 0.3519 - val_acc: 0.8992\n",
      "Epoch 112/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1218 - acc: 0.9577 - val_loss: 0.3504 - val_acc: 0.8989\n",
      "Epoch 113/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1233 - acc: 0.9575 - val_loss: 0.3508 - val_acc: 0.8990\n",
      "Epoch 114/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1199 - acc: 0.9574 - val_loss: 0.3504 - val_acc: 0.8993\n",
      "Epoch 115/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1235 - acc: 0.9570 - val_loss: 0.3515 - val_acc: 0.8989\n",
      "Epoch 116/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1206 - acc: 0.9585 - val_loss: 0.3493 - val_acc: 0.8994\n",
      "Epoch 117/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1205 - acc: 0.9581 - val_loss: 0.3492 - val_acc: 0.8985\n",
      "Epoch 118/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1235 - acc: 0.9569 - val_loss: 0.3520 - val_acc: 0.8994\n",
      "Epoch 119/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1224 - acc: 0.9577 - val_loss: 0.3514 - val_acc: 0.8987\n",
      "Epoch 120/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1208 - acc: 0.9571 - val_loss: 0.3498 - val_acc: 0.8989\n",
      "Epoch 121/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1205 - acc: 0.9564 - val_loss: 0.3502 - val_acc: 0.8990\n",
      "Epoch 122/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1227 - acc: 0.9577 - val_loss: 0.3520 - val_acc: 0.8989\n",
      "Epoch 123/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1201 - acc: 0.9576 - val_loss: 0.3520 - val_acc: 0.8988\n",
      "Epoch 124/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1177 - acc: 0.9587 - val_loss: 0.3515 - val_acc: 0.8993\n",
      "Epoch 125/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1235 - acc: 0.9568 - val_loss: 0.3517 - val_acc: 0.8999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [0.45516522298036649,\n",
       "  0.62925088225858195,\n",
       "  0.69449791462328869,\n",
       "  0.73243503368623675,\n",
       "  0.76016602504318409,\n",
       "  0.77584134615384615,\n",
       "  0.79337267174733017,\n",
       "  0.80068976580044915,\n",
       "  0.81526708369611511,\n",
       "  0.82174366376015251,\n",
       "  0.82296679497606529,\n",
       "  0.8328721526726951,\n",
       "  0.83948909207571387,\n",
       "  0.84311838307975762,\n",
       "  0.84805101056798049,\n",
       "  0.8515800449149824,\n",
       "  0.85663298042990055,\n",
       "  0.85753205128205123,\n",
       "  0.86237556199730403,\n",
       "  0.86385145975604893,\n",
       "  0.8649943855889608,\n",
       "  0.87113009303817779,\n",
       "  0.87223291624651755,\n",
       "  0.87381697142778159,\n",
       "  0.87850898301559344,\n",
       "  0.88177735003516355,\n",
       "  0.88223853065755686,\n",
       "  0.8864092076096276,\n",
       "  0.88472489573307667,\n",
       "  0.88890224358974357,\n",
       "  0.89141779060385207,\n",
       "  0.89274542831556136,\n",
       "  0.89080044913070111,\n",
       "  0.89471045875534017,\n",
       "  0.89823949312146445,\n",
       "  0.90012431825473216,\n",
       "  0.90038498558216384,\n",
       "  0.90136750076380834,\n",
       "  0.90154796276560645,\n",
       "  0.90218349358974359,\n",
       "  0.9033397560174754,\n",
       "  0.90537776712197926,\n",
       "  0.90593920438229214,\n",
       "  0.90527751046493721,\n",
       "  0.90880654475457168,\n",
       "  0.92615094642284246,\n",
       "  0.93231169871794872,\n",
       "  0.93350594089286942,\n",
       "  0.93469281358370082,\n",
       "  0.93567708333333333,\n",
       "  0.93766056515118523,\n",
       "  0.9384223612639091,\n",
       "  0.93653753613064139,\n",
       "  0.93739974336208043,\n",
       "  0.93792107797869895,\n",
       "  0.94052775104266928,\n",
       "  0.93918431187655094,\n",
       "  0.93932467119640983,\n",
       "  0.94240785256410253,\n",
       "  0.94097222226050392,\n",
       "  0.94116939360949337,\n",
       "  0.94153031765133444,\n",
       "  0.9417308309080511,\n",
       "  0.94285370544779934,\n",
       "  0.94309432146294514,\n",
       "  0.94235242221995652,\n",
       "  0.94205165221058562,\n",
       "  0.94469842799474002,\n",
       "  0.94391025641025639,\n",
       "  0.94295396214308635,\n",
       "  0.94437760671132798,\n",
       "  0.94514691714836219,\n",
       "  0.94536012191209495,\n",
       "  0.94459817135682045,\n",
       "  0.94473157051282053,\n",
       "  0.94536769430302015,\n",
       "  0.94542027588719779,\n",
       "  0.94542027592544264,\n",
       "  0.9468439204745619,\n",
       "  0.94600176449804152,\n",
       "  0.94632258585794327,\n",
       "  0.94658325310888525,\n",
       "  0.94732515235187387,\n",
       "  0.9463025344500452,\n",
       "  0.94870869423817628,\n",
       "  0.9525841346153846,\n",
       "  0.95381743736043523,\n",
       "  0.95420673076923079,\n",
       "  0.95393786119511281,\n",
       "  0.95590712227116115,\n",
       "  0.9553256335838276,\n",
       "  0.95482435037510727,\n",
       "  0.95306490384615383,\n",
       "  0.95498476098812957,\n",
       "  0.95441955687835878,\n",
       "  0.95466393966647267,\n",
       "  0.95620789216579749,\n",
       "  0.95402644230769229,\n",
       "  0.95664902145678243,\n",
       "  0.95431920355837851,\n",
       "  0.95662897016361892,\n",
       "  0.95645032051282053,\n",
       "  0.95550337183069711,\n",
       "  0.95370147575886921,\n",
       "  0.95678938077664122,\n",
       "  0.95620789224228719,\n",
       "  0.95819297401347447,\n",
       "  0.95859400066076506,\n",
       "  0.95751122870734384,\n",
       "  0.9565287134683319,\n",
       "  0.95536573630401178,\n",
       "  0.95773237179487181,\n",
       "  0.95753050736685785,\n",
       "  0.9574109721267916,\n",
       "  0.95694979142790848,\n",
       "  0.95847355769230769,\n",
       "  0.95813262684649969,\n",
       "  0.95687099358974359,\n",
       "  0.95771174202142784,\n",
       "  0.95702999679178702,\n",
       "  0.95642662168927273,\n",
       "  0.95767163937773347,\n",
       "  0.9575520833333333,\n",
       "  0.95877488758522655,\n",
       "  0.95682948351594777],\n",
       " 'loss': [1.4813120110049476,\n",
       "  1.0403141976167729,\n",
       "  0.85956479178279643,\n",
       "  0.76022433270848178,\n",
       "  0.69139731848205477,\n",
       "  0.64467381116671441,\n",
       "  0.59732312306656465,\n",
       "  0.57039315982778216,\n",
       "  0.53836898120848609,\n",
       "  0.51574222116773238,\n",
       "  0.51015765551462133,\n",
       "  0.48278464023639345,\n",
       "  0.46531790307518911,\n",
       "  0.44922772123525262,\n",
       "  0.437860643706874,\n",
       "  0.42892005369377934,\n",
       "  0.41277124540791282,\n",
       "  0.4068806836238274,\n",
       "  0.39668925515182829,\n",
       "  0.38678621807884705,\n",
       "  0.38437463575959169,\n",
       "  0.36612124642118798,\n",
       "  0.36364997636059521,\n",
       "  0.35874457892065137,\n",
       "  0.34594391726667312,\n",
       "  0.34297686042715275,\n",
       "  0.33783724046418939,\n",
       "  0.32799287300519847,\n",
       "  0.32717970829190524,\n",
       "  0.32338162973905221,\n",
       "  0.3110756593766546,\n",
       "  0.30756837634425305,\n",
       "  0.31051623691225955,\n",
       "  0.30430259194403153,\n",
       "  0.29228423089792915,\n",
       "  0.28956445962678251,\n",
       "  0.28979998239921689,\n",
       "  0.28313478858072405,\n",
       "  0.27957354400415702,\n",
       "  0.28087348093589148,\n",
       "  0.2750593353692124,\n",
       "  0.27195854033745365,\n",
       "  0.27121036396716547,\n",
       "  0.27212804803050478,\n",
       "  0.25929349257389933,\n",
       "  0.21404060058804861,\n",
       "  0.19644997337689765,\n",
       "  0.19130246805872914,\n",
       "  0.18623547071461347,\n",
       "  0.18291184008121492,\n",
       "  0.17998680740346032,\n",
       "  0.17741469101413229,\n",
       "  0.18039937001851111,\n",
       "  0.17608449066922494,\n",
       "  0.17450573375908121,\n",
       "  0.17017093411251485,\n",
       "  0.17293261038184279,\n",
       "  0.17303618917795646,\n",
       "  0.16606754878392585,\n",
       "  0.16941548830320532,\n",
       "  0.167355487418932,\n",
       "  0.16293209573665718,\n",
       "  0.16593908460468371,\n",
       "  0.16374923677485761,\n",
       "  0.16188172508900006,\n",
       "  0.16337082943053516,\n",
       "  0.16186374163432576,\n",
       "  0.15751173944571939,\n",
       "  0.15665945426011696,\n",
       "  0.15912349542670423,\n",
       "  0.15652225865723424,\n",
       "  0.15765755665210401,\n",
       "  0.15450282088926981,\n",
       "  0.15856451078661368,\n",
       "  0.15333927139066733,\n",
       "  0.15464034916769639,\n",
       "  0.15353110090333144,\n",
       "  0.15356064648784273,\n",
       "  0.14850181039036717,\n",
       "  0.15381825531967031,\n",
       "  0.14973472839924706,\n",
       "  0.15024350632315536,\n",
       "  0.14819422568845031,\n",
       "  0.15184703506565186,\n",
       "  0.14580291503891563,\n",
       "  0.13453791478696542,\n",
       "  0.13071957527969078,\n",
       "  0.13137078757087389,\n",
       "  0.13065335597883607,\n",
       "  0.12830011171811967,\n",
       "  0.1286145425881183,\n",
       "  0.12628790938896287,\n",
       "  0.1306037365912627,\n",
       "  0.12883551376711913,\n",
       "  0.12852474042216247,\n",
       "  0.12862150354820603,\n",
       "  0.12699074760667398,\n",
       "  0.12906059564497227,\n",
       "  0.12420257573895321,\n",
       "  0.12772267301762494,\n",
       "  0.12574559312946032,\n",
       "  0.12597427117900969,\n",
       "  0.12544186639389551,\n",
       "  0.12598697271318746,\n",
       "  0.12331639487448127,\n",
       "  0.12232640212091606,\n",
       "  0.12050042062146869,\n",
       "  0.11939596453724016,\n",
       "  0.12357399752019957,\n",
       "  0.12244850885688321,\n",
       "  0.12744832744258391,\n",
       "  0.12179957691293497,\n",
       "  0.12320697905738613,\n",
       "  0.11991197146645027,\n",
       "  0.12350882591729291,\n",
       "  0.12062978165654036,\n",
       "  0.12034863133555279,\n",
       "  0.12352355685180579,\n",
       "  0.1224036834151614,\n",
       "  0.12089138562537977,\n",
       "  0.12037721098273246,\n",
       "  0.12267191710000165,\n",
       "  0.12010274997983987,\n",
       "  0.11769683339185032,\n",
       "  0.12352201359314838],\n",
       " 'val_acc': [0.48530000000000001,\n",
       "  0.64070000000000005,\n",
       "  0.7006,\n",
       "  0.60970000000000002,\n",
       "  0.64419999999999999,\n",
       "  0.72019999999999995,\n",
       "  0.73699999999999999,\n",
       "  0.78790000000000004,\n",
       "  0.81730000000000003,\n",
       "  0.72940000000000005,\n",
       "  0.76939999999999997,\n",
       "  0.7873,\n",
       "  0.79049999999999998,\n",
       "  0.81320000000000003,\n",
       "  0.77249999999999996,\n",
       "  0.76790000000000003,\n",
       "  0.82579999999999998,\n",
       "  0.82779999999999998,\n",
       "  0.82140000000000002,\n",
       "  0.83309999999999995,\n",
       "  0.83140000000000003,\n",
       "  0.83389999999999997,\n",
       "  0.81299999999999994,\n",
       "  0.82840000000000003,\n",
       "  0.86399999999999999,\n",
       "  0.85170000000000001,\n",
       "  0.84279999999999999,\n",
       "  0.83279999999999998,\n",
       "  0.86150000000000004,\n",
       "  0.87160000000000004,\n",
       "  0.84670000000000001,\n",
       "  0.81530000000000002,\n",
       "  0.85150000000000003,\n",
       "  0.84670000000000001,\n",
       "  0.85599999999999998,\n",
       "  0.85809999999999997,\n",
       "  0.85229999999999995,\n",
       "  0.85389999999999999,\n",
       "  0.81259999999999999,\n",
       "  0.87129999999999996,\n",
       "  0.86639999999999995,\n",
       "  0.84419999999999995,\n",
       "  0.85799999999999998,\n",
       "  0.81899999999999995,\n",
       "  0.85660000000000003,\n",
       "  0.89439999999999997,\n",
       "  0.89039999999999997,\n",
       "  0.89049999999999996,\n",
       "  0.89449999999999996,\n",
       "  0.89739999999999998,\n",
       "  0.89270000000000005,\n",
       "  0.89480000000000004,\n",
       "  0.89649999999999996,\n",
       "  0.8982,\n",
       "  0.89410000000000001,\n",
       "  0.89510000000000001,\n",
       "  0.89649999999999996,\n",
       "  0.8911,\n",
       "  0.89419999999999999,\n",
       "  0.8931,\n",
       "  0.89270000000000005,\n",
       "  0.88959999999999995,\n",
       "  0.89019999999999999,\n",
       "  0.88990000000000002,\n",
       "  0.8901,\n",
       "  0.89729999999999999,\n",
       "  0.89459999999999995,\n",
       "  0.89190000000000003,\n",
       "  0.89319999999999999,\n",
       "  0.89059999999999995,\n",
       "  0.89170000000000005,\n",
       "  0.89610000000000001,\n",
       "  0.89380000000000004,\n",
       "  0.88639999999999997,\n",
       "  0.8972,\n",
       "  0.89029999999999998,\n",
       "  0.89329999999999998,\n",
       "  0.8952,\n",
       "  0.8952,\n",
       "  0.88770000000000004,\n",
       "  0.8891,\n",
       "  0.89500000000000002,\n",
       "  0.89239999999999997,\n",
       "  0.89370000000000005,\n",
       "  0.89480000000000004,\n",
       "  0.89490000000000003,\n",
       "  0.89870000000000005,\n",
       "  0.90049999999999997,\n",
       "  0.89859999999999995,\n",
       "  0.89859999999999995,\n",
       "  0.89910000000000001,\n",
       "  0.89870000000000005,\n",
       "  0.89990000000000003,\n",
       "  0.89959999999999996,\n",
       "  0.89890000000000003,\n",
       "  0.89900000000000002,\n",
       "  0.89800000000000002,\n",
       "  0.89970000000000006,\n",
       "  0.89890000000000003,\n",
       "  0.8992,\n",
       "  0.89810000000000001,\n",
       "  0.89939999999999998,\n",
       "  0.89859999999999995,\n",
       "  0.89610000000000001,\n",
       "  0.89739999999999998,\n",
       "  0.89949999999999997,\n",
       "  0.89910000000000001,\n",
       "  0.89890000000000003,\n",
       "  0.90000000000000002,\n",
       "  0.89839999999999998,\n",
       "  0.8992,\n",
       "  0.89890000000000003,\n",
       "  0.89900000000000002,\n",
       "  0.89930000114440922,\n",
       "  0.89890000000000003,\n",
       "  0.89939999999999998,\n",
       "  0.89849999999999997,\n",
       "  0.89939999999999998,\n",
       "  0.89870000000000005,\n",
       "  0.89890000000000003,\n",
       "  0.89900000000000002,\n",
       "  0.89890000000000003,\n",
       "  0.89880000000000004,\n",
       "  0.89929999999999999,\n",
       "  0.89990000000000003],\n",
       " 'val_loss': [1.6290396179199218,\n",
       "  1.0974550788879394,\n",
       "  0.86135747814178465,\n",
       "  1.1223259395599365,\n",
       "  1.2395962468147277,\n",
       "  0.87976081390380856,\n",
       "  0.81047158575057987,\n",
       "  0.63298860225677489,\n",
       "  0.52857776603698725,\n",
       "  0.92763197197914127,\n",
       "  0.77429340996742246,\n",
       "  0.68281930875778196,\n",
       "  0.63407366619110106,\n",
       "  0.60200386724472044,\n",
       "  0.76501079711914066,\n",
       "  0.7474588916778564,\n",
       "  0.52402661724090571,\n",
       "  0.53610511274337769,\n",
       "  0.58145004634857178,\n",
       "  0.48641567630767824,\n",
       "  0.56039879498481748,\n",
       "  0.48942719583511352,\n",
       "  0.62148433609008791,\n",
       "  0.56241670172214508,\n",
       "  0.41965029315948488,\n",
       "  0.49231105213165283,\n",
       "  0.50819765148162843,\n",
       "  0.56833849725723262,\n",
       "  0.43189923782348633,\n",
       "  0.40109563689231875,\n",
       "  0.51280583248138423,\n",
       "  0.64576169157028196,\n",
       "  0.49519560213088987,\n",
       "  0.53073125658035281,\n",
       "  0.45228718818426134,\n",
       "  0.46560015492439272,\n",
       "  0.49338647675514219,\n",
       "  0.47678253412246702,\n",
       "  0.65471650757789612,\n",
       "  0.40371660242080687,\n",
       "  0.42426775546073914,\n",
       "  0.53260400042533873,\n",
       "  0.43607266554832458,\n",
       "  0.62061083221435542,\n",
       "  0.45194998140335085,\n",
       "  0.32305340332984922,\n",
       "  0.3303196862578392,\n",
       "  0.34101229732036592,\n",
       "  0.33106837985515597,\n",
       "  0.33366652307510375,\n",
       "  0.34546662316322324,\n",
       "  0.33834450850486758,\n",
       "  0.33690602059364316,\n",
       "  0.34080143032073973,\n",
       "  0.33954188179969785,\n",
       "  0.3387676114797592,\n",
       "  0.32974318882226944,\n",
       "  0.35294038805961608,\n",
       "  0.35183924467563626,\n",
       "  0.35234433805942533,\n",
       "  0.36093835463523866,\n",
       "  0.34609980778694155,\n",
       "  0.36184190621376039,\n",
       "  0.37232997276782992,\n",
       "  0.37119639310836794,\n",
       "  0.33913208079338075,\n",
       "  0.33688098983764647,\n",
       "  0.35509206253290176,\n",
       "  0.36466729483604432,\n",
       "  0.36816293374300002,\n",
       "  0.36118263096809389,\n",
       "  0.3401462980747223,\n",
       "  0.3500927647590637,\n",
       "  0.3915828004360199,\n",
       "  0.35259134049415586,\n",
       "  0.35926256318092348,\n",
       "  0.35556262004375455,\n",
       "  0.36568643736839296,\n",
       "  0.35683698694705962,\n",
       "  0.37452842769622802,\n",
       "  0.37332688910961154,\n",
       "  0.35875577859878538,\n",
       "  0.36615411338806153,\n",
       "  0.36596272597312929,\n",
       "  0.36961054763793944,\n",
       "  0.3505131151199341,\n",
       "  0.34397228994369505,\n",
       "  0.34096820192337035,\n",
       "  0.34071859006881716,\n",
       "  0.34120446641445162,\n",
       "  0.34256885862350461,\n",
       "  0.34877846250534056,\n",
       "  0.34315791301727294,\n",
       "  0.34139988021850587,\n",
       "  0.34640620980262754,\n",
       "  0.34804005122184756,\n",
       "  0.35090694966316222,\n",
       "  0.3441815207481384,\n",
       "  0.34795212798118591,\n",
       "  0.34943905436992645,\n",
       "  0.35082969417572024,\n",
       "  0.3497772210121155,\n",
       "  0.34987991034984589,\n",
       "  0.35331451468467712,\n",
       "  0.35202934346199033,\n",
       "  0.34967165331840516,\n",
       "  0.34916613383293149,\n",
       "  0.35167178483009337,\n",
       "  0.35047896625995634,\n",
       "  0.35052124693393705,\n",
       "  0.35193892741203309,\n",
       "  0.35040552048683166,\n",
       "  0.35077358243465423,\n",
       "  0.35042806297540663,\n",
       "  0.35145947589874266,\n",
       "  0.34928653752803801,\n",
       "  0.3492220881462097,\n",
       "  0.35201773662567137,\n",
       "  0.35137236166000368,\n",
       "  0.34977285642623901,\n",
       "  0.35015249371528623,\n",
       "  0.35195190677642824,\n",
       "  0.35197277195453641,\n",
       "  0.35149095153808596,\n",
       "  0.351701328086853]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 1/125\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 1.4940 - acc: 0.4544 - val_loss: 1.4668 - val_acc: 0.5072\n",
      "Epoch 2/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 1.0675 - acc: 0.6198 - val_loss: 1.4434 - val_acc: 0.5801\n",
      "Epoch 3/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.8773 - acc: 0.6913 - val_loss: 1.0260 - val_acc: 0.6340\n",
      "Epoch 4/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.7745 - acc: 0.7304 - val_loss: 0.7134 - val_acc: 0.7496\n",
      "Epoch 5/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.7033 - acc: 0.7547 - val_loss: 1.0043 - val_acc: 0.6880\n",
      "Epoch 6/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.6596 - acc: 0.7692 - val_loss: 0.7626 - val_acc: 0.7510\n",
      "Epoch 7/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.6146 - acc: 0.7872 - val_loss: 0.9213 - val_acc: 0.7130\n",
      "Epoch 8/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5855 - acc: 0.7989 - val_loss: 0.6410 - val_acc: 0.7880\n",
      "Epoch 9/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5542 - acc: 0.8080 - val_loss: 0.6857 - val_acc: 0.7756\n",
      "Epoch 10/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5342 - acc: 0.8142 - val_loss: 0.5552 - val_acc: 0.8056\n",
      "Epoch 11/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.5097 - acc: 0.8227 - val_loss: 0.5380 - val_acc: 0.8174\n",
      "Epoch 12/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4950 - acc: 0.8301 - val_loss: 0.9062 - val_acc: 0.7365\n",
      "Epoch 13/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4731 - acc: 0.8357 - val_loss: 0.5462 - val_acc: 0.8130\n",
      "Epoch 14/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4660 - acc: 0.8387 - val_loss: 0.6795 - val_acc: 0.7935\n",
      "Epoch 15/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4525 - acc: 0.8426 - val_loss: 0.6226 - val_acc: 0.8047\n",
      "Epoch 16/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4352 - acc: 0.8495 - val_loss: 0.8488 - val_acc: 0.7426\n",
      "Epoch 17/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4201 - acc: 0.8533 - val_loss: 0.4966 - val_acc: 0.8326\n",
      "Epoch 18/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4152 - acc: 0.8560 - val_loss: 0.5314 - val_acc: 0.8291\n",
      "Epoch 19/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.4062 - acc: 0.8597 - val_loss: 0.5018 - val_acc: 0.8347\n",
      "Epoch 20/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3916 - acc: 0.8635 - val_loss: 0.4955 - val_acc: 0.8357\n",
      "Epoch 21/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3904 - acc: 0.8658 - val_loss: 0.5916 - val_acc: 0.8194\n",
      "Epoch 22/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3759 - acc: 0.8687 - val_loss: 0.7434 - val_acc: 0.7830\n",
      "Epoch 23/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3739 - acc: 0.8701 - val_loss: 0.5775 - val_acc: 0.8179\n",
      "Epoch 24/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3641 - acc: 0.8746 - val_loss: 0.4382 - val_acc: 0.8557\n",
      "Epoch 25/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3493 - acc: 0.8778 - val_loss: 0.5093 - val_acc: 0.8445\n",
      "Epoch 26/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3498 - acc: 0.8786 - val_loss: 0.3935 - val_acc: 0.8675\n",
      "Epoch 27/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3450 - acc: 0.8814 - val_loss: 0.4646 - val_acc: 0.8496\n",
      "Epoch 28/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3379 - acc: 0.8833 - val_loss: 0.5722 - val_acc: 0.8183\n",
      "Epoch 29/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3367 - acc: 0.8834 - val_loss: 0.4647 - val_acc: 0.8549\n",
      "Epoch 30/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3233 - acc: 0.8877 - val_loss: 0.4972 - val_acc: 0.8361\n",
      "Epoch 31/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3256 - acc: 0.8868 - val_loss: 0.4281 - val_acc: 0.8583\n",
      "Epoch 32/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3179 - acc: 0.8904 - val_loss: 0.4584 - val_acc: 0.8557\n",
      "Epoch 33/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3130 - acc: 0.8906 - val_loss: 0.3678 - val_acc: 0.8787\n",
      "Epoch 34/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3077 - acc: 0.8918 - val_loss: 0.4817 - val_acc: 0.8495\n",
      "Epoch 35/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3054 - acc: 0.8931 - val_loss: 0.4569 - val_acc: 0.8573\n",
      "Epoch 36/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.3002 - acc: 0.8954 - val_loss: 0.5151 - val_acc: 0.8433\n",
      "Epoch 37/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2942 - acc: 0.8989 - val_loss: 0.4414 - val_acc: 0.8565\n",
      "Epoch 38/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2899 - acc: 0.8985 - val_loss: 0.4592 - val_acc: 0.8559\n",
      "Epoch 39/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2867 - acc: 0.8997 - val_loss: 0.4689 - val_acc: 0.8621\n",
      "Epoch 40/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2824 - acc: 0.9031 - val_loss: 0.5055 - val_acc: 0.8519\n",
      "Epoch 41/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2847 - acc: 0.9003 - val_loss: 0.4960 - val_acc: 0.8507\n",
      "Epoch 42/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2754 - acc: 0.9044 - val_loss: 0.4004 - val_acc: 0.8709\n",
      "Epoch 43/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2758 - acc: 0.9042 - val_loss: 0.6340 - val_acc: 0.8115\n",
      "Epoch 44/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2699 - acc: 0.9056 - val_loss: 0.4916 - val_acc: 0.8547\n",
      "Epoch 45/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2699 - acc: 0.9056 - val_loss: 0.4899 - val_acc: 0.8410\n",
      "Epoch 46/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2183 - acc: 0.9236 - val_loss: 0.3440 - val_acc: 0.8891\n",
      "Epoch 47/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.2024 - acc: 0.9295 - val_loss: 0.3353 - val_acc: 0.8911\n",
      "Epoch 48/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1937 - acc: 0.9340 - val_loss: 0.3382 - val_acc: 0.8948\n",
      "Epoch 49/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1915 - acc: 0.9334 - val_loss: 0.3200 - val_acc: 0.8991\n",
      "Epoch 50/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1855 - acc: 0.9359 - val_loss: 0.3382 - val_acc: 0.8968\n",
      "Epoch 51/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1885 - acc: 0.9339 - val_loss: 0.3409 - val_acc: 0.8952\n",
      "Epoch 52/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1839 - acc: 0.9344 - val_loss: 0.3460 - val_acc: 0.8971\n",
      "Epoch 53/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1804 - acc: 0.9373 - val_loss: 0.3294 - val_acc: 0.8998\n",
      "Epoch 54/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1819 - acc: 0.9354 - val_loss: 0.3318 - val_acc: 0.8990\n",
      "Epoch 55/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1788 - acc: 0.9373 - val_loss: 0.3343 - val_acc: 0.8997\n",
      "Epoch 56/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1746 - acc: 0.9392 - val_loss: 0.3411 - val_acc: 0.8963\n",
      "Epoch 57/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1793 - acc: 0.9364 - val_loss: 0.3240 - val_acc: 0.9013\n",
      "Epoch 58/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1755 - acc: 0.9379 - val_loss: 0.3527 - val_acc: 0.8946\n",
      "Epoch 59/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1721 - acc: 0.9396 - val_loss: 0.3325 - val_acc: 0.9003\n",
      "Epoch 60/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1723 - acc: 0.9407 - val_loss: 0.3421 - val_acc: 0.8974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1706 - acc: 0.9395 - val_loss: 0.3379 - val_acc: 0.8975\n",
      "Epoch 62/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1709 - acc: 0.9402 - val_loss: 0.3501 - val_acc: 0.8959\n",
      "Epoch 63/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1704 - acc: 0.9392 - val_loss: 0.3442 - val_acc: 0.8973\n",
      "Epoch 64/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1682 - acc: 0.9407 - val_loss: 0.3307 - val_acc: 0.9019\n",
      "Epoch 65/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1658 - acc: 0.9410 - val_loss: 0.3424 - val_acc: 0.8994\n",
      "Epoch 66/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1659 - acc: 0.9415 - val_loss: 0.3350 - val_acc: 0.8998\n",
      "Epoch 67/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1647 - acc: 0.9423 - val_loss: 0.3375 - val_acc: 0.8990\n",
      "Epoch 68/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1660 - acc: 0.9405 - val_loss: 0.3521 - val_acc: 0.8967\n",
      "Epoch 69/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1638 - acc: 0.9413 - val_loss: 0.3403 - val_acc: 0.9018\n",
      "Epoch 70/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1628 - acc: 0.9421 - val_loss: 0.3489 - val_acc: 0.8983\n",
      "Epoch 71/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1637 - acc: 0.9420 - val_loss: 0.3417 - val_acc: 0.8957\n",
      "Epoch 72/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1623 - acc: 0.9438 - val_loss: 0.3616 - val_acc: 0.8942\n",
      "Epoch 73/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1634 - acc: 0.9424 - val_loss: 0.3488 - val_acc: 0.8994\n",
      "Epoch 74/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1560 - acc: 0.9449 - val_loss: 0.3448 - val_acc: 0.8972\n",
      "Epoch 75/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1584 - acc: 0.9432 - val_loss: 0.3559 - val_acc: 0.8957\n",
      "Epoch 76/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1549 - acc: 0.9457 - val_loss: 0.3442 - val_acc: 0.8986\n",
      "Epoch 77/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1576 - acc: 0.9449 - val_loss: 0.3879 - val_acc: 0.8907\n",
      "Epoch 78/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1562 - acc: 0.9449 - val_loss: 0.3518 - val_acc: 0.8967\n",
      "Epoch 79/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1577 - acc: 0.9444 - val_loss: 0.3485 - val_acc: 0.8979\n",
      "Epoch 80/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1495 - acc: 0.9472 - val_loss: 0.3479 - val_acc: 0.8995\n",
      "Epoch 81/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1543 - acc: 0.9462 - val_loss: 0.3631 - val_acc: 0.8951\n",
      "Epoch 82/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1556 - acc: 0.9443 - val_loss: 0.3603 - val_acc: 0.8962\n",
      "Epoch 83/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1511 - acc: 0.9468 - val_loss: 0.3661 - val_acc: 0.8930\n",
      "Epoch 84/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1525 - acc: 0.9457 - val_loss: 0.3963 - val_acc: 0.8914\n",
      "Epoch 85/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1553 - acc: 0.9447 - val_loss: 0.3600 - val_acc: 0.8958\n",
      "Epoch 86/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1436 - acc: 0.9499 - val_loss: 0.3323 - val_acc: 0.9022\n",
      "Epoch 87/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1352 - acc: 0.9528 - val_loss: 0.3357 - val_acc: 0.9020\n",
      "Epoch 88/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1381 - acc: 0.9511 - val_loss: 0.3346 - val_acc: 0.9039\n",
      "Epoch 89/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1337 - acc: 0.9527 - val_loss: 0.3414 - val_acc: 0.9015\n",
      "Epoch 90/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1360 - acc: 0.9518 - val_loss: 0.3343 - val_acc: 0.9027\n",
      "Epoch 91/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1337 - acc: 0.9532 - val_loss: 0.3382 - val_acc: 0.9020\n",
      "Epoch 92/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1299 - acc: 0.9543 - val_loss: 0.3356 - val_acc: 0.9032\n",
      "Epoch 93/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1314 - acc: 0.9523 - val_loss: 0.3378 - val_acc: 0.9035\n",
      "Epoch 94/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1335 - acc: 0.9540 - val_loss: 0.3395 - val_acc: 0.9042\n",
      "Epoch 95/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1347 - acc: 0.9524 - val_loss: 0.3403 - val_acc: 0.9033\n",
      "Epoch 96/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1299 - acc: 0.9547 - val_loss: 0.3330 - val_acc: 0.9039\n",
      "Epoch 97/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1301 - acc: 0.9554 - val_loss: 0.3357 - val_acc: 0.9034\n",
      "Epoch 98/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1290 - acc: 0.9547 - val_loss: 0.3408 - val_acc: 0.9031\n",
      "Epoch 99/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1301 - acc: 0.9547 - val_loss: 0.3434 - val_acc: 0.9022\n",
      "Epoch 100/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1308 - acc: 0.9542 - val_loss: 0.3372 - val_acc: 0.9048\n",
      "Epoch 101/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1296 - acc: 0.9547 - val_loss: 0.3406 - val_acc: 0.9019\n",
      "Epoch 102/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1266 - acc: 0.9560 - val_loss: 0.3414 - val_acc: 0.9026\n",
      "Epoch 103/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1281 - acc: 0.9546 - val_loss: 0.3447 - val_acc: 0.9023\n",
      "Epoch 104/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1285 - acc: 0.9545 - val_loss: 0.3361 - val_acc: 0.9049\n",
      "Epoch 105/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1272 - acc: 0.9558 - val_loss: 0.3422 - val_acc: 0.9034\n",
      "Epoch 106/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1266 - acc: 0.9543 - val_loss: 0.3398 - val_acc: 0.9048\n",
      "Epoch 107/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1261 - acc: 0.9548 - val_loss: 0.3372 - val_acc: 0.9046\n",
      "Epoch 108/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1264 - acc: 0.9565 - val_loss: 0.3388 - val_acc: 0.9039\n",
      "Epoch 109/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1241 - acc: 0.9555 - val_loss: 0.3390 - val_acc: 0.9048\n",
      "Epoch 110/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1257 - acc: 0.9555 - val_loss: 0.3385 - val_acc: 0.9045\n",
      "Epoch 111/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1256 - acc: 0.9560 - val_loss: 0.3384 - val_acc: 0.9048\n",
      "Epoch 112/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1248 - acc: 0.9557 - val_loss: 0.3392 - val_acc: 0.9049\n",
      "Epoch 113/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1227 - acc: 0.9566 - val_loss: 0.3383 - val_acc: 0.9049\n",
      "Epoch 114/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1232 - acc: 0.9561 - val_loss: 0.3375 - val_acc: 0.9042\n",
      "Epoch 115/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1252 - acc: 0.9561 - val_loss: 0.3402 - val_acc: 0.9042\n",
      "Epoch 116/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1237 - acc: 0.9576 - val_loss: 0.3398 - val_acc: 0.9039\n",
      "Epoch 117/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1242 - acc: 0.9559 - val_loss: 0.3398 - val_acc: 0.9044\n",
      "Epoch 118/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1220 - acc: 0.9566 - val_loss: 0.3386 - val_acc: 0.9047\n",
      "Epoch 119/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1248 - acc: 0.9556 - val_loss: 0.3376 - val_acc: 0.9040\n",
      "Epoch 120/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1247 - acc: 0.9569 - val_loss: 0.3393 - val_acc: 0.9046\n",
      "Epoch 121/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1221 - acc: 0.9572 - val_loss: 0.3386 - val_acc: 0.9045\n",
      "Epoch 122/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1239 - acc: 0.9561 - val_loss: 0.3379 - val_acc: 0.9046\n",
      "Epoch 123/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1234 - acc: 0.9573 - val_loss: 0.3399 - val_acc: 0.9049\n",
      "Epoch 124/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1234 - acc: 0.9567 - val_loss: 0.3410 - val_acc: 0.9030\n",
      "Epoch 125/125\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.1238 - acc: 0.9559 - val_loss: 0.3389 - val_acc: 0.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [0.45432306705165221,\n",
       "  0.61974655117099775,\n",
       "  0.69128970163618864,\n",
       "  0.73044871794871791,\n",
       "  0.75463631980757573,\n",
       "  0.76924927813294686,\n",
       "  0.78715511709977537,\n",
       "  0.79894529998704034,\n",
       "  0.80797275641025645,\n",
       "  0.81412572256249349,\n",
       "  0.82274623033057281,\n",
       "  0.83010506899570247,\n",
       "  0.83565928779583076,\n",
       "  0.83868703878113271,\n",
       "  0.84255694578119988,\n",
       "  0.84949470644850822,\n",
       "  0.85334456211716692,\n",
       "  0.85603144052589331,\n",
       "  0.85982114208559213,\n",
       "  0.86345043314700332,\n",
       "  0.86579643886441948,\n",
       "  0.86874398460057745,\n",
       "  0.870147577760921,\n",
       "  0.87459935897435892,\n",
       "  0.87785003211303791,\n",
       "  0.87862929098492137,\n",
       "  0.88141642603156733,\n",
       "  0.88326114855938553,\n",
       "  0.88346166187346953,\n",
       "  0.88767244148835722,\n",
       "  0.886810234161306,\n",
       "  0.89037937115200216,\n",
       "  0.89064003847943385,\n",
       "  0.89178685897435894,\n",
       "  0.89312379570365641,\n",
       "  0.89545235799832879,\n",
       "  0.89886108435688017,\n",
       "  0.89854026307346813,\n",
       "  0.89972329160744158,\n",
       "  0.90313201800423781,\n",
       "  0.90036493426987785,\n",
       "  0.90439525184472247,\n",
       "  0.90423484119345521,\n",
       "  0.90559833176747173,\n",
       "  0.90551812638447071,\n",
       "  0.92352422197009643,\n",
       "  0.92949951878716863,\n",
       "  0.93403111966634589,\n",
       "  0.93334937443670496,\n",
       "  0.93585579082451076,\n",
       "  0.93393086304754869,\n",
       "  0.93439204359345229,\n",
       "  0.93729948668591589,\n",
       "  0.93543471282668933,\n",
       "  0.93727943537363001,\n",
       "  0.93918431185742846,\n",
       "  0.93643727943535449,\n",
       "  0.93782082132165689,\n",
       "  0.93954523576541249,\n",
       "  0.94060795638742534,\n",
       "  0.93952518447224898,\n",
       "  0.94014677570766469,\n",
       "  0.93926451720218451,\n",
       "  0.94074519230769227,\n",
       "  0.94102903436612428,\n",
       "  0.94147398840102459,\n",
       "  0.94235242221995652,\n",
       "  0.94052775104266928,\n",
       "  0.94126965026653531,\n",
       "  0.9421318575362192,\n",
       "  0.94199149825460526,\n",
       "  0.94381616943189262,\n",
       "  0.94233237090767064,\n",
       "  0.94487888995829328,\n",
       "  0.94321462945139556,\n",
       "  0.945660891883221,\n",
       "  0.9448788899391708,\n",
       "  0.94491899260198764,\n",
       "  0.94443776064818585,\n",
       "  0.94724494704536266,\n",
       "  0.94614212379877793,\n",
       "  0.94433092948717945,\n",
       "  0.94683285167604669,\n",
       "  0.94566089190234348,\n",
       "  0.94469842799474002,\n",
       "  0.94991987179487181,\n",
       "  0.95281390496454865,\n",
       "  0.95114182692307692,\n",
       "  0.95269348105330764,\n",
       "  0.95177654798190714,\n",
       "  0.95318014116137306,\n",
       "  0.95434695512820511,\n",
       "  0.95233220935786622,\n",
       "  0.95396214312454586,\n",
       "  0.95249839585524243,\n",
       "  0.95476419638088206,\n",
       "  0.95540583896682851,\n",
       "  0.9547275641025641,\n",
       "  0.95474068716158833,\n",
       "  0.95424286172601858,\n",
       "  0.95470404236753437,\n",
       "  0.95594722485748818,\n",
       "  0.95464743589743595,\n",
       "  0.95456005138086064,\n",
       "  0.95574671154340418,\n",
       "  0.95428685897435894,\n",
       "  0.95488118179807624,\n",
       "  0.95650866215604602,\n",
       "  0.95554619826756493,\n",
       "  0.95552614691703408,\n",
       "  0.95600737888995835,\n",
       "  0.95574919871794872,\n",
       "  0.95656711628747892,\n",
       "  0.95602743024048908,\n",
       "  0.95604748159101993,\n",
       "  0.95763221153846156,\n",
       "  0.95586464346871591,\n",
       "  0.9566490214759048,\n",
       "  0.9556063523000351,\n",
       "  0.95687099358974359,\n",
       "  0.95720937694964225,\n",
       "  0.95612768685928629,\n",
       "  0.95725160256410258,\n",
       "  0.95670761080912159,\n",
       "  0.95594722489573303],\n",
       " 'loss': [1.4941449515667335,\n",
       "  1.0676496052611972,\n",
       "  0.87737322805935192,\n",
       "  0.77451441165728452,\n",
       "  0.70323767316364372,\n",
       "  0.65949667440915594,\n",
       "  0.61463906815084923,\n",
       "  0.58543997190302288,\n",
       "  0.55422323017548292,\n",
       "  0.53429599338873268,\n",
       "  0.50972246365513529,\n",
       "  0.4948595114384548,\n",
       "  0.4731375338712257,\n",
       "  0.46610657566244645,\n",
       "  0.45259230124250527,\n",
       "  0.43522043192008003,\n",
       "  0.42008788571512234,\n",
       "  0.41514647531899496,\n",
       "  0.40603918198557054,\n",
       "  0.39177627178350627,\n",
       "  0.39039441036764994,\n",
       "  0.37581925221769941,\n",
       "  0.37382129511658796,\n",
       "  0.36414319689457231,\n",
       "  0.34921508105848564,\n",
       "  0.34981506550430602,\n",
       "  0.34498734472461107,\n",
       "  0.33801505379295133,\n",
       "  0.33656767526038534,\n",
       "  0.32338332562902472,\n",
       "  0.32566671496520716,\n",
       "  0.31786590310714163,\n",
       "  0.31282908581065794,\n",
       "  0.30771068858030515,\n",
       "  0.30534750463377608,\n",
       "  0.30004104961368339,\n",
       "  0.29435665256746846,\n",
       "  0.28982381333821394,\n",
       "  0.28673705919013792,\n",
       "  0.28241329789544128,\n",
       "  0.28460031132075431,\n",
       "  0.27528687648984307,\n",
       "  0.27569420303447834,\n",
       "  0.26990710564595904,\n",
       "  0.27003113378077165,\n",
       "  0.21839788139229752,\n",
       "  0.20229583434619541,\n",
       "  0.1937020709442335,\n",
       "  0.19158002432766807,\n",
       "  0.18545767932623519,\n",
       "  0.18837902169790566,\n",
       "  0.18387745327011759,\n",
       "  0.18044384954485865,\n",
       "  0.18178415084290589,\n",
       "  0.17893662803976973,\n",
       "  0.17466064899404499,\n",
       "  0.17917931777833554,\n",
       "  0.17553495215822726,\n",
       "  0.17213094107302329,\n",
       "  0.17233938241199992,\n",
       "  0.17053347651989825,\n",
       "  0.17085941771226393,\n",
       "  0.17038083448408503,\n",
       "  0.16824150658570802,\n",
       "  0.16564103970552127,\n",
       "  0.16597579025311124,\n",
       "  0.16467234101248049,\n",
       "  0.16608593318184714,\n",
       "  0.163859992485552,\n",
       "  0.16282467847169496,\n",
       "  0.16365943158288623,\n",
       "  0.16228382774641548,\n",
       "  0.16342385924508795,\n",
       "  0.15599995710488732,\n",
       "  0.15846385317503509,\n",
       "  0.15493276506844031,\n",
       "  0.15759216021193043,\n",
       "  0.15625483829517336,\n",
       "  0.15775322807037873,\n",
       "  0.14954731279950054,\n",
       "  0.15434536252996653,\n",
       "  0.15558387954265643,\n",
       "  0.1509761233779966,\n",
       "  0.15255663380203699,\n",
       "  0.15528338312873252,\n",
       "  0.14358709715306758,\n",
       "  0.13513914089441759,\n",
       "  0.13808738282666758,\n",
       "  0.13370474371233657,\n",
       "  0.13594373887094657,\n",
       "  0.13367601140095403,\n",
       "  0.12989656678759134,\n",
       "  0.13120794664726246,\n",
       "  0.1334977022201578,\n",
       "  0.13468545696790454,\n",
       "  0.1298877412419232,\n",
       "  0.13017634226605032,\n",
       "  0.12897023669420143,\n",
       "  0.13011879490433631,\n",
       "  0.13071343939025928,\n",
       "  0.12972888478726616,\n",
       "  0.12655980224348545,\n",
       "  0.12811106555163859,\n",
       "  0.12845986494142503,\n",
       "  0.12724479428651742,\n",
       "  0.12663568482758142,\n",
       "  0.12607099790324672,\n",
       "  0.12644028759247453,\n",
       "  0.12407824414297293,\n",
       "  0.12566709398917369,\n",
       "  0.12554798058431654,\n",
       "  0.124843936222486,\n",
       "  0.1227482211852043,\n",
       "  0.12330609263495486,\n",
       "  0.1252122879754973,\n",
       "  0.12369959320968542,\n",
       "  0.12419329486504992,\n",
       "  0.12200565155228629,\n",
       "  0.1248202973837496,\n",
       "  0.1247186659811399,\n",
       "  0.12204709602430147,\n",
       "  0.12390446355509613,\n",
       "  0.12343660538586286,\n",
       "  0.12336832769669702,\n",
       "  0.12376571626169085],\n",
       " 'val_acc': [0.50719999999999998,\n",
       "  0.58009999999999995,\n",
       "  0.63400000000000001,\n",
       "  0.74960000000000004,\n",
       "  0.68799999999999994,\n",
       "  0.751,\n",
       "  0.71299999999999997,\n",
       "  0.78800000000000003,\n",
       "  0.77559999999999996,\n",
       "  0.80559999999999998,\n",
       "  0.81740000000000002,\n",
       "  0.73650000000000004,\n",
       "  0.81299999999999994,\n",
       "  0.79349999999999998,\n",
       "  0.80469999999999997,\n",
       "  0.74260000000000004,\n",
       "  0.83260000000000001,\n",
       "  0.82909999999999995,\n",
       "  0.8347,\n",
       "  0.8357,\n",
       "  0.81940000000000002,\n",
       "  0.78300000000000003,\n",
       "  0.81789999999999996,\n",
       "  0.85570000000000002,\n",
       "  0.84450000000000003,\n",
       "  0.86750000000000005,\n",
       "  0.84960000000000002,\n",
       "  0.81830000000000003,\n",
       "  0.85489999999999999,\n",
       "  0.83609999999999995,\n",
       "  0.85829999999999995,\n",
       "  0.85570000000000002,\n",
       "  0.87870000000000004,\n",
       "  0.84950000000000003,\n",
       "  0.85729999999999995,\n",
       "  0.84330000000000005,\n",
       "  0.85650000000000004,\n",
       "  0.85589999999999999,\n",
       "  0.86209999999999998,\n",
       "  0.85189999999999999,\n",
       "  0.85070000000000001,\n",
       "  0.87090000000000001,\n",
       "  0.8115,\n",
       "  0.85470000000000002,\n",
       "  0.84099999999999997,\n",
       "  0.8891,\n",
       "  0.8911,\n",
       "  0.89480000000000004,\n",
       "  0.89910000000000001,\n",
       "  0.89680000000000004,\n",
       "  0.8952,\n",
       "  0.89710000000000001,\n",
       "  0.89980000000000004,\n",
       "  0.89900000000000002,\n",
       "  0.89970000000000006,\n",
       "  0.89629999999999999,\n",
       "  0.90129999999999999,\n",
       "  0.89459999999999995,\n",
       "  0.90029999999999999,\n",
       "  0.89739999999999998,\n",
       "  0.89749999999999996,\n",
       "  0.89590000000000003,\n",
       "  0.89729999999999999,\n",
       "  0.90190000000000003,\n",
       "  0.89939999999999998,\n",
       "  0.89980000000000004,\n",
       "  0.89900000000000002,\n",
       "  0.89670000000000005,\n",
       "  0.90180000000000005,\n",
       "  0.89829999999999999,\n",
       "  0.89570000000000005,\n",
       "  0.89419999999999999,\n",
       "  0.89939999999999998,\n",
       "  0.8972,\n",
       "  0.89570000000000005,\n",
       "  0.89859999999999995,\n",
       "  0.89070000000000005,\n",
       "  0.89670000000000005,\n",
       "  0.89790000000000003,\n",
       "  0.89949999999999997,\n",
       "  0.89510000000000001,\n",
       "  0.8962,\n",
       "  0.89300000000000002,\n",
       "  0.89139999999999997,\n",
       "  0.89580000000000004,\n",
       "  0.9022,\n",
       "  0.90200000000000002,\n",
       "  0.90390000000000004,\n",
       "  0.90149999999999997,\n",
       "  0.90269999999999995,\n",
       "  0.90200000000000002,\n",
       "  0.9032,\n",
       "  0.90349999999999997,\n",
       "  0.9042,\n",
       "  0.90329999999999999,\n",
       "  0.90390000000000004,\n",
       "  0.90339999999999998,\n",
       "  0.90310000000000001,\n",
       "  0.9022,\n",
       "  0.90480000000000005,\n",
       "  0.90190000000000003,\n",
       "  0.90259999999999996,\n",
       "  0.90229999999999999,\n",
       "  0.90490000000000004,\n",
       "  0.90339999999999998,\n",
       "  0.90480000000000005,\n",
       "  0.90459999999999996,\n",
       "  0.90390000000000004,\n",
       "  0.90480000000000005,\n",
       "  0.90449999999999997,\n",
       "  0.90480000000000005,\n",
       "  0.90490000000000004,\n",
       "  0.90490000000000004,\n",
       "  0.9042,\n",
       "  0.9042,\n",
       "  0.90390000000000004,\n",
       "  0.90439999999999998,\n",
       "  0.90469999999999995,\n",
       "  0.90400000000000003,\n",
       "  0.90459999999999996,\n",
       "  0.90449999999999997,\n",
       "  0.90459999999999996,\n",
       "  0.90490000000000004,\n",
       "  0.90300000000000002,\n",
       "  0.90349999999999997],\n",
       " 'val_loss': [1.4667663772583008,\n",
       "  1.4433705123901368,\n",
       "  1.0259819515228272,\n",
       "  0.71340259609222412,\n",
       "  1.0043070800781251,\n",
       "  0.76262585430145269,\n",
       "  0.92126553878784179,\n",
       "  0.64095609598159786,\n",
       "  0.68571142463684087,\n",
       "  0.55520332651138304,\n",
       "  0.53804019470214848,\n",
       "  0.90619456920623775,\n",
       "  0.54617919979095464,\n",
       "  0.67949824085235599,\n",
       "  0.6226112384796143,\n",
       "  0.84877609062194825,\n",
       "  0.49660934629440306,\n",
       "  0.5313543676137924,\n",
       "  0.50176295971870422,\n",
       "  0.49551408371925354,\n",
       "  0.59159865789413457,\n",
       "  0.74343881616592411,\n",
       "  0.57750684919357298,\n",
       "  0.43816891000270841,\n",
       "  0.50934552006721501,\n",
       "  0.39350912289619444,\n",
       "  0.46455815782547,\n",
       "  0.57223698425292968,\n",
       "  0.46474908063411713,\n",
       "  0.49720368394851683,\n",
       "  0.42811489753723142,\n",
       "  0.45837286181449888,\n",
       "  0.36777081322669986,\n",
       "  0.4816590934753418,\n",
       "  0.45691875867843629,\n",
       "  0.51509282550811764,\n",
       "  0.44141390252113344,\n",
       "  0.45916364660263059,\n",
       "  0.46889755401611327,\n",
       "  0.50549774303436279,\n",
       "  0.49597130200862882,\n",
       "  0.40040699129104612,\n",
       "  0.63398381633758549,\n",
       "  0.4915886875152588,\n",
       "  0.48988865551948546,\n",
       "  0.34399163084030149,\n",
       "  0.33532468453645708,\n",
       "  0.33820859205722809,\n",
       "  0.32001571340560914,\n",
       "  0.33819579849243164,\n",
       "  0.34091283711194992,\n",
       "  0.34602269974946975,\n",
       "  0.3294181780576706,\n",
       "  0.3317686687231064,\n",
       "  0.33430084795951842,\n",
       "  0.34107609279155732,\n",
       "  0.32400547906160354,\n",
       "  0.35272951979637146,\n",
       "  0.33250422203540803,\n",
       "  0.34209424765110014,\n",
       "  0.33793554573059081,\n",
       "  0.35014632840156557,\n",
       "  0.34416548912525174,\n",
       "  0.33069564346075059,\n",
       "  0.3423736432790756,\n",
       "  0.33503563647270201,\n",
       "  0.33751976377964021,\n",
       "  0.35213136074543,\n",
       "  0.3402840262413025,\n",
       "  0.3488902460575104,\n",
       "  0.34169396427869797,\n",
       "  0.36157536764144899,\n",
       "  0.34883765169382097,\n",
       "  0.34483581571578981,\n",
       "  0.3559135093331337,\n",
       "  0.34424018225669861,\n",
       "  0.38793368656635285,\n",
       "  0.35180074222087859,\n",
       "  0.34852465331554411,\n",
       "  0.34794758148193361,\n",
       "  0.36313914645910261,\n",
       "  0.36028519200086595,\n",
       "  0.36613351924419402,\n",
       "  0.39626655142307282,\n",
       "  0.35995953938961028,\n",
       "  0.33226784056425096,\n",
       "  0.33568820017576217,\n",
       "  0.33458572243452073,\n",
       "  0.34142194805145265,\n",
       "  0.33427650340795517,\n",
       "  0.33824771113395691,\n",
       "  0.33562461107969283,\n",
       "  0.33779569162130357,\n",
       "  0.33946551039218903,\n",
       "  0.34029984579086303,\n",
       "  0.33295268938541411,\n",
       "  0.33570328483581541,\n",
       "  0.34084282279014588,\n",
       "  0.34336859846115114,\n",
       "  0.33721726210117342,\n",
       "  0.34064538643360137,\n",
       "  0.34141445600986481,\n",
       "  0.34466882096529006,\n",
       "  0.33614954862594604,\n",
       "  0.34219070270061491,\n",
       "  0.33978556051254272,\n",
       "  0.33715916492938997,\n",
       "  0.33881438276767728,\n",
       "  0.33902114129066468,\n",
       "  0.33850633695125582,\n",
       "  0.33837733142375948,\n",
       "  0.33917319144010544,\n",
       "  0.33826246463060378,\n",
       "  0.33754450323581697,\n",
       "  0.34022639796733856,\n",
       "  0.33976066454648973,\n",
       "  0.33982035071849825,\n",
       "  0.33862323629856111,\n",
       "  0.33757732980251315,\n",
       "  0.33934669398069384,\n",
       "  0.33860851526260377,\n",
       "  0.33787282441854477,\n",
       "  0.33992407149076465,\n",
       "  0.34103172414302824,\n",
       "  0.33887350826263429]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using He initialization\n",
    "run(\"act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 1/125\n",
      "390/390 [==============================] - 38s 98ms/step - loss: 1.4768 - acc: 0.4611 - val_loss: 1.2710 - val_acc: 0.5389\n",
      "Epoch 2/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 1.0489 - acc: 0.6280 - val_loss: 1.0244 - val_acc: 0.6582\n",
      "Epoch 3/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.8856 - acc: 0.6896 - val_loss: 1.2191 - val_acc: 0.6441\n",
      "Epoch 4/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.7900 - acc: 0.7241 - val_loss: 0.7798 - val_acc: 0.7328\n",
      "Epoch 5/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.7344 - acc: 0.7438 - val_loss: 0.8886 - val_acc: 0.7097\n",
      "Epoch 6/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.6785 - acc: 0.7619 - val_loss: 0.8854 - val_acc: 0.7118\n",
      "Epoch 7/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.6376 - acc: 0.7794 - val_loss: 0.7887 - val_acc: 0.7432\n",
      "Epoch 8/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.6009 - acc: 0.7941 - val_loss: 0.7822 - val_acc: 0.7518\n",
      "Epoch 9/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.5741 - acc: 0.8022 - val_loss: 1.0464 - val_acc: 0.7253\n",
      "Epoch 10/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.5620 - acc: 0.8050 - val_loss: 0.6779 - val_acc: 0.7804\n",
      "Epoch 11/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.5309 - acc: 0.8150 - val_loss: 0.7132 - val_acc: 0.7692\n",
      "Epoch 12/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.5151 - acc: 0.8213 - val_loss: 0.6177 - val_acc: 0.7940\n",
      "Epoch 13/125\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.4985 - acc: 0.8271 - val_loss: 0.6986 - val_acc: 0.7804\n",
      "Epoch 14/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4866 - acc: 0.8319 - val_loss: 0.7407 - val_acc: 0.7761\n",
      "Epoch 15/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4791 - acc: 0.8344 - val_loss: 0.6486 - val_acc: 0.8058\n",
      "Epoch 16/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4702 - acc: 0.8380 - val_loss: 0.5251 - val_acc: 0.8277\n",
      "Epoch 17/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4593 - acc: 0.8393 - val_loss: 0.6178 - val_acc: 0.8089\n",
      "Epoch 18/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.4426 - acc: 0.8445 - val_loss: 0.8391 - val_acc: 0.7626\n",
      "Epoch 19/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.4346 - acc: 0.8497 - val_loss: 0.5403 - val_acc: 0.8278\n",
      "Epoch 20/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4258 - acc: 0.8536 - val_loss: 0.6709 - val_acc: 0.7985\n",
      "Epoch 21/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4159 - acc: 0.8546 - val_loss: 0.5962 - val_acc: 0.8206\n",
      "Epoch 22/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4124 - acc: 0.8567 - val_loss: 0.4895 - val_acc: 0.8415\n",
      "Epoch 23/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4103 - acc: 0.8592 - val_loss: 0.6154 - val_acc: 0.8170\n",
      "Epoch 24/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4021 - acc: 0.8606 - val_loss: 0.6165 - val_acc: 0.8183\n",
      "Epoch 25/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3895 - acc: 0.8652 - val_loss: 0.6653 - val_acc: 0.8068\n",
      "Epoch 26/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3853 - acc: 0.8664 - val_loss: 0.6248 - val_acc: 0.8145\n",
      "Epoch 27/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3781 - acc: 0.8681 - val_loss: 0.4673 - val_acc: 0.8528\n",
      "Epoch 28/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3744 - acc: 0.8701 - val_loss: 0.5107 - val_acc: 0.8428\n",
      "Epoch 29/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.3684 - acc: 0.8726 - val_loss: 0.7829 - val_acc: 0.8004\n",
      "Epoch 30/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3601 - acc: 0.8743 - val_loss: 0.4817 - val_acc: 0.8495\n",
      "Epoch 31/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3593 - acc: 0.8747 - val_loss: 0.6442 - val_acc: 0.8150\n",
      "Epoch 32/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3534 - acc: 0.8781 - val_loss: 0.5138 - val_acc: 0.8457\n",
      "Epoch 33/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.3516 - acc: 0.8777 - val_loss: 0.5943 - val_acc: 0.8326\n",
      "Epoch 34/125\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.3439 - acc: 0.8801 - val_loss: 0.4431 - val_acc: 0.8623\n",
      "Epoch 35/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.3484 - acc: 0.8776 - val_loss: 0.5234 - val_acc: 0.8486\n",
      "Epoch 36/125\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.3406 - acc: 0.8817 - val_loss: 0.4648 - val_acc: 0.8570\n",
      "Epoch 37/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.3392 - acc: 0.8814 - val_loss: 0.4510 - val_acc: 0.8620\n",
      "Epoch 38/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3274 - acc: 0.8868 - val_loss: 0.5350 - val_acc: 0.8460\n",
      "Epoch 39/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3307 - acc: 0.8853 - val_loss: 0.6065 - val_acc: 0.8329\n",
      "Epoch 40/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3233 - acc: 0.8858 - val_loss: 0.6715 - val_acc: 0.8163\n",
      "Epoch 41/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3164 - acc: 0.8888 - val_loss: 0.5544 - val_acc: 0.8438\n",
      "Epoch 42/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.3193 - acc: 0.8886 - val_loss: 0.6115 - val_acc: 0.8378\n",
      "Epoch 43/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.3175 - acc: 0.8883 - val_loss: 0.7162 - val_acc: 0.8210\n",
      "Epoch 44/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.3132 - acc: 0.8910 - val_loss: 0.5312 - val_acc: 0.8469\n",
      "Epoch 45/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.3065 - acc: 0.8941 - val_loss: 0.5941 - val_acc: 0.8303\n",
      "Epoch 46/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2619 - acc: 0.9084 - val_loss: 0.3822 - val_acc: 0.8865\n",
      "Epoch 47/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2457 - acc: 0.9147 - val_loss: 0.4242 - val_acc: 0.8783\n",
      "Epoch 48/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2411 - acc: 0.9160 - val_loss: 0.4527 - val_acc: 0.8712\n",
      "Epoch 49/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2383 - acc: 0.9171 - val_loss: 0.4574 - val_acc: 0.8722\n",
      "Epoch 50/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2380 - acc: 0.9168 - val_loss: 0.4665 - val_acc: 0.8723\n",
      "Epoch 51/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2351 - acc: 0.9188 - val_loss: 0.4677 - val_acc: 0.8694\n",
      "Epoch 52/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2389 - acc: 0.9174 - val_loss: 0.4237 - val_acc: 0.8824\n",
      "Epoch 53/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2299 - acc: 0.9205 - val_loss: 0.4548 - val_acc: 0.8740\n",
      "Epoch 54/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2347 - acc: 0.9183 - val_loss: 0.4402 - val_acc: 0.8778\n",
      "Epoch 55/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2293 - acc: 0.9191 - val_loss: 0.5287 - val_acc: 0.8621\n",
      "Epoch 56/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2269 - acc: 0.9184 - val_loss: 0.4762 - val_acc: 0.8707\n",
      "Epoch 57/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2243 - acc: 0.9218 - val_loss: 0.4287 - val_acc: 0.8806\n",
      "Epoch 58/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2242 - acc: 0.9221 - val_loss: 0.5057 - val_acc: 0.8642\n",
      "Epoch 59/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2242 - acc: 0.9211 - val_loss: 0.4945 - val_acc: 0.8686\n",
      "Epoch 60/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2225 - acc: 0.9226 - val_loss: 0.5152 - val_acc: 0.8669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2213 - acc: 0.9219 - val_loss: 0.4686 - val_acc: 0.8735\n",
      "Epoch 62/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2217 - acc: 0.9226 - val_loss: 0.4080 - val_acc: 0.8831\n",
      "Epoch 63/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2178 - acc: 0.9234 - val_loss: 0.4831 - val_acc: 0.8690\n",
      "Epoch 64/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2170 - acc: 0.9238 - val_loss: 0.4440 - val_acc: 0.8769\n",
      "Epoch 65/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2186 - acc: 0.9219 - val_loss: 0.4198 - val_acc: 0.8844\n",
      "Epoch 66/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2203 - acc: 0.9231 - val_loss: 0.4683 - val_acc: 0.8764\n",
      "Epoch 67/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2174 - acc: 0.9245 - val_loss: 0.4119 - val_acc: 0.8848\n",
      "Epoch 68/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2139 - acc: 0.9252 - val_loss: 0.4560 - val_acc: 0.8751\n",
      "Epoch 69/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2130 - acc: 0.9249 - val_loss: 0.4157 - val_acc: 0.8877\n",
      "Epoch 70/125\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.2166 - acc: 0.9251 - val_loss: 0.4857 - val_acc: 0.8700\n",
      "Epoch 71/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2100 - acc: 0.9245 - val_loss: 0.4187 - val_acc: 0.8830\n",
      "Epoch 72/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2133 - acc: 0.9257 - val_loss: 0.5987 - val_acc: 0.8534\n",
      "Epoch 73/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2159 - acc: 0.9242 - val_loss: 0.4187 - val_acc: 0.8853\n",
      "Epoch 74/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2123 - acc: 0.9248 - val_loss: 0.4752 - val_acc: 0.8771\n",
      "Epoch 75/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2095 - acc: 0.9258 - val_loss: 0.4467 - val_acc: 0.8830\n",
      "Epoch 76/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2135 - acc: 0.9257 - val_loss: 0.4482 - val_acc: 0.8798\n",
      "Epoch 77/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2087 - acc: 0.9259 - val_loss: 0.4651 - val_acc: 0.8749\n",
      "Epoch 78/125\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.2128 - acc: 0.9246 - val_loss: 0.4517 - val_acc: 0.8797\n",
      "Epoch 79/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2054 - acc: 0.9279 - val_loss: 0.4311 - val_acc: 0.8827\n",
      "Epoch 80/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2065 - acc: 0.9264 - val_loss: 0.4905 - val_acc: 0.8673\n",
      "Epoch 81/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2083 - acc: 0.9266 - val_loss: 0.4851 - val_acc: 0.8744\n",
      "Epoch 82/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2056 - acc: 0.9270 - val_loss: 0.4097 - val_acc: 0.8833\n",
      "Epoch 83/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2023 - acc: 0.9287 - val_loss: 0.4052 - val_acc: 0.8875\n",
      "Epoch 84/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2025 - acc: 0.9284 - val_loss: 0.4499 - val_acc: 0.8798\n",
      "Epoch 85/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.2074 - acc: 0.9264 - val_loss: 0.4751 - val_acc: 0.8742\n",
      "Epoch 86/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1923 - acc: 0.9312 - val_loss: 0.4449 - val_acc: 0.8809\n",
      "Epoch 87/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1897 - acc: 0.9331 - val_loss: 0.4548 - val_acc: 0.8778\n",
      "Epoch 88/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1905 - acc: 0.9334 - val_loss: 0.4756 - val_acc: 0.8744\n",
      "Epoch 89/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1870 - acc: 0.9336 - val_loss: 0.4566 - val_acc: 0.8784\n",
      "Epoch 90/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1850 - acc: 0.9353 - val_loss: 0.4429 - val_acc: 0.8824\n",
      "Epoch 91/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1831 - acc: 0.9367 - val_loss: 0.4450 - val_acc: 0.8823\n",
      "Epoch 92/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1847 - acc: 0.9351 - val_loss: 0.4306 - val_acc: 0.8845\n",
      "Epoch 93/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1868 - acc: 0.9338 - val_loss: 0.4543 - val_acc: 0.8785\n",
      "Epoch 94/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1864 - acc: 0.9348 - val_loss: 0.4505 - val_acc: 0.8801\n",
      "Epoch 95/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1847 - acc: 0.9344 - val_loss: 0.4446 - val_acc: 0.8823\n",
      "Epoch 96/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1875 - acc: 0.9342 - val_loss: 0.4559 - val_acc: 0.8802\n",
      "Epoch 97/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1858 - acc: 0.9347 - val_loss: 0.4638 - val_acc: 0.8792\n",
      "Epoch 98/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1889 - acc: 0.9342 - val_loss: 0.4213 - val_acc: 0.8865\n",
      "Epoch 99/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1835 - acc: 0.9345 - val_loss: 0.4396 - val_acc: 0.8834\n",
      "Epoch 100/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1841 - acc: 0.9351 - val_loss: 0.4454 - val_acc: 0.8815\n",
      "Epoch 101/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1819 - acc: 0.9354 - val_loss: 0.4394 - val_acc: 0.8830\n",
      "Epoch 102/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1796 - acc: 0.9369 - val_loss: 0.4223 - val_acc: 0.8882\n",
      "Epoch 103/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1806 - acc: 0.9368 - val_loss: 0.4227 - val_acc: 0.8869\n",
      "Epoch 104/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1796 - acc: 0.9365 - val_loss: 0.4443 - val_acc: 0.8828\n",
      "Epoch 105/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1792 - acc: 0.9363 - val_loss: 0.4231 - val_acc: 0.8883\n",
      "Epoch 106/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1812 - acc: 0.9350 - val_loss: 0.4318 - val_acc: 0.8852\n",
      "Epoch 107/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1767 - acc: 0.9376 - val_loss: 0.4431 - val_acc: 0.8841\n",
      "Epoch 108/125\n",
      "390/390 [==============================] - 36s 94ms/step - loss: 0.1784 - acc: 0.9376 - val_loss: 0.4354 - val_acc: 0.8851\n",
      "Epoch 109/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1769 - acc: 0.9371 - val_loss: 0.4359 - val_acc: 0.8854\n",
      "Epoch 110/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1767 - acc: 0.9385 - val_loss: 0.4464 - val_acc: 0.8827\n",
      "Epoch 111/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1744 - acc: 0.9375 - val_loss: 0.4391 - val_acc: 0.8854\n",
      "Epoch 112/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1776 - acc: 0.9375 - val_loss: 0.4449 - val_acc: 0.8841\n",
      "Epoch 113/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1806 - acc: 0.9359 - val_loss: 0.4477 - val_acc: 0.8835\n",
      "Epoch 114/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1750 - acc: 0.9378 - val_loss: 0.4406 - val_acc: 0.8846\n",
      "Epoch 115/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1782 - acc: 0.9372 - val_loss: 0.4417 - val_acc: 0.8841\n",
      "Epoch 116/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1787 - acc: 0.9379 - val_loss: 0.4511 - val_acc: 0.8822\n",
      "Epoch 117/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1797 - acc: 0.9348 - val_loss: 0.4430 - val_acc: 0.8841\n",
      "Epoch 118/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1784 - acc: 0.9370 - val_loss: 0.4437 - val_acc: 0.8840\n",
      "Epoch 119/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1783 - acc: 0.9369 - val_loss: 0.4454 - val_acc: 0.8826\n",
      "Epoch 120/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1776 - acc: 0.9358 - val_loss: 0.4389 - val_acc: 0.8855\n",
      "Epoch 121/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1740 - acc: 0.9376 - val_loss: 0.4409 - val_acc: 0.8842\n",
      "Epoch 122/125\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.1757 - acc: 0.9377 - val_loss: 0.4519 - val_acc: 0.8821\n",
      "Epoch 123/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1767 - acc: 0.9384 - val_loss: 0.4370 - val_acc: 0.8857\n",
      "Epoch 124/125\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.1752 - acc: 0.9383 - val_loss: 0.4460 - val_acc: 0.8835\n",
      "Epoch 125/125\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.1786 - acc: 0.9364 - val_loss: 0.4421 - val_acc: 0.8846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [0.46130093039133857,\n",
       "  0.62798764836072996,\n",
       "  0.68954523576541249,\n",
       "  0.72413378252140181,\n",
       "  0.74378408730163914,\n",
       "  0.76197064481257326,\n",
       "  0.77931504649996641,\n",
       "  0.79415303172306406,\n",
       "  0.80219361561783464,\n",
       "  0.80504090471607315,\n",
       "  0.81496631380147877,\n",
       "  0.82136268850163763,\n",
       "  0.82713747190901354,\n",
       "  0.83180943214629455,\n",
       "  0.83439605393622374,\n",
       "  0.83790503687532736,\n",
       "  0.83928857878075225,\n",
       "  0.84446182228412081,\n",
       "  0.84961501445608101,\n",
       "  0.8535851780558229,\n",
       "  0.85462784726993757,\n",
       "  0.85675328838010611,\n",
       "  0.85921960218158488,\n",
       "  0.86054299003541723,\n",
       "  0.86515479627847292,\n",
       "  0.86643808145036594,\n",
       "  0.86806223929444681,\n",
       "  0.8701676291496967,\n",
       "  0.87267404555662498,\n",
       "  0.87427815203105252,\n",
       "  0.87461902474148523,\n",
       "  0.87810795636830286,\n",
       "  0.87768429487179489,\n",
       "  0.88003773276210218,\n",
       "  0.87758662173256186,\n",
       "  0.88175729870375508,\n",
       "  0.88141642608893467,\n",
       "  0.88685033688149006,\n",
       "  0.88528633301251203,\n",
       "  0.88574751359666049,\n",
       "  0.8887953159898605,\n",
       "  0.88853464873891863,\n",
       "  0.88831408407430368,\n",
       "  0.8910210137570711,\n",
       "  0.89405048076923077,\n",
       "  0.90839755940912015,\n",
       "  0.91470163620776535,\n",
       "  0.91600497276843418,\n",
       "  0.91708774466448806,\n",
       "  0.91678685897435896,\n",
       "  0.91875401407231405,\n",
       "  0.91734841191543004,\n",
       "  0.92045272435897441,\n",
       "  0.91829238919087841,\n",
       "  0.91913060897435894,\n",
       "  0.91845295439948615,\n",
       "  0.92183493589743593,\n",
       "  0.92200545915901932,\n",
       "  0.92115816486390467,\n",
       "  0.9225961538461539,\n",
       "  0.92184489400783409,\n",
       "  0.92258180941302381,\n",
       "  0.92340391405813582,\n",
       "  0.92375801282051284,\n",
       "  0.92186496469479917,\n",
       "  0.9230830927556013,\n",
       "  0.92452678857876158,\n",
       "  0.92522858515893336,\n",
       "  0.92493990384615388,\n",
       "  0.92509633909453926,\n",
       "  0.92446663454629152,\n",
       "  0.92570981715098,\n",
       "  0.92416586461341033,\n",
       "  0.92472730187372321,\n",
       "  0.92589027915277811,\n",
       "  0.92568976580044915,\n",
       "  0.92595043312788083,\n",
       "  0.92454683989104758,\n",
       "  0.92791546354853727,\n",
       "  0.92637151104921245,\n",
       "  0.92657202442066389,\n",
       "  0.92704326923076918,\n",
       "  0.92870905587668595,\n",
       "  0.92845684957305397,\n",
       "  0.92641161373115177,\n",
       "  0.93125000000000002,\n",
       "  0.93310452795748378,\n",
       "  0.93342957972409368,\n",
       "  0.93363381410256407,\n",
       "  0.9353925819073875,\n",
       "  0.93679820340070585,\n",
       "  0.93503368619852123,\n",
       "  0.93387070899595614,\n",
       "  0.93483317294180446,\n",
       "  0.93435496794871797,\n",
       "  0.93420841359678719,\n",
       "  0.93469281364106815,\n",
       "  0.93419153029849067,\n",
       "  0.93453240293243356,\n",
       "  0.93511389154327729,\n",
       "  0.93535450757754546,\n",
       "  0.93681825477035907,\n",
       "  0.93675810071876653,\n",
       "  0.93649743339133484,\n",
       "  0.9362969201154957,\n",
       "  0.93503605769230769,\n",
       "  0.93760025663791957,\n",
       "  0.93764049455992438,\n",
       "  0.9371190246841179,\n",
       "  0.93846246386935861,\n",
       "  0.93747994866859163,\n",
       "  0.93747994870683649,\n",
       "  0.935917467948718,\n",
       "  0.93780076997112605,\n",
       "  0.93719923002887395,\n",
       "  0.93794112929098494,\n",
       "  0.93481053313385165,\n",
       "  0.9369591346153846,\n",
       "  0.93689788052035816,\n",
       "  0.93585579084363324,\n",
       "  0.93762019230769234,\n",
       "  0.93776091845202458,\n",
       "  0.93838225860109226,\n",
       "  0.93832131410256414,\n",
       "  0.93641618495195744],\n",
       " 'loss': [1.4761938276220523,\n",
       "  1.0488371538129189,\n",
       "  0.88568946429464657,\n",
       "  0.79007375888576636,\n",
       "  0.7341736883049329,\n",
       "  0.67842856423381359,\n",
       "  0.63772318200266509,\n",
       "  0.60084106207352861,\n",
       "  0.57396149329355906,\n",
       "  0.56193787892124081,\n",
       "  0.53095823055970426,\n",
       "  0.51499447497106876,\n",
       "  0.49842760147557336,\n",
       "  0.48671712337451978,\n",
       "  0.47904579013939808,\n",
       "  0.47019023509181612,\n",
       "  0.45931912491556387,\n",
       "  0.44272430695743947,\n",
       "  0.43479655247527055,\n",
       "  0.42581524152307509,\n",
       "  0.4158496247926583,\n",
       "  0.41240590472308575,\n",
       "  0.41022457704928045,\n",
       "  0.4020735506335244,\n",
       "  0.38960144779488642,\n",
       "  0.38508877044386464,\n",
       "  0.3781265734593609,\n",
       "  0.37438775645374756,\n",
       "  0.3683786329203475,\n",
       "  0.3601642204738405,\n",
       "  0.35938607734252442,\n",
       "  0.35337069347610756,\n",
       "  0.35161499747863184,\n",
       "  0.34394955467588256,\n",
       "  0.34839705426340345,\n",
       "  0.34067041163724471,\n",
       "  0.33930179452834924,\n",
       "  0.32729993172092703,\n",
       "  0.33077661012815368,\n",
       "  0.32339914381637919,\n",
       "  0.31645597947267223,\n",
       "  0.31933851882858388,\n",
       "  0.31751587111138363,\n",
       "  0.31320795469418677,\n",
       "  0.30652897766767406,\n",
       "  0.26193389366395825,\n",
       "  0.24569318379237554,\n",
       "  0.2410363147837786,\n",
       "  0.23836600069610361,\n",
       "  0.23800474858054749,\n",
       "  0.23523525697972886,\n",
       "  0.23897290119843334,\n",
       "  0.2299125434878545,\n",
       "  0.2346959786876012,\n",
       "  0.2293206848968298,\n",
       "  0.22686541706859567,\n",
       "  0.22426325804912128,\n",
       "  0.22434355992783164,\n",
       "  0.22413279787829415,\n",
       "  0.22254869817541195,\n",
       "  0.22133540413321481,\n",
       "  0.22181028512031328,\n",
       "  0.2177655988486103,\n",
       "  0.21699978543015627,\n",
       "  0.21858250291380427,\n",
       "  0.220371295358265,\n",
       "  0.21743846799189898,\n",
       "  0.21389931468558993,\n",
       "  0.21297250447364954,\n",
       "  0.21653344784130557,\n",
       "  0.2100639364487627,\n",
       "  0.21336398163513376,\n",
       "  0.2158598515862718,\n",
       "  0.21233035597255837,\n",
       "  0.20936637532646013,\n",
       "  0.21355869972174238,\n",
       "  0.20868389570430032,\n",
       "  0.21289589659770713,\n",
       "  0.20539096086729708,\n",
       "  0.2065738378224711,\n",
       "  0.20837121917234233,\n",
       "  0.20563547957019929,\n",
       "  0.20236611742389915,\n",
       "  0.20242282593330588,\n",
       "  0.20743308738615027,\n",
       "  0.19229769064829899,\n",
       "  0.18966095255748844,\n",
       "  0.19047093228399659,\n",
       "  0.18700625407390106,\n",
       "  0.18492050002841667,\n",
       "  0.1830387658460193,\n",
       "  0.18474310649906095,\n",
       "  0.18666772691148728,\n",
       "  0.18634298681868625,\n",
       "  0.18467023924757273,\n",
       "  0.18742936567744922,\n",
       "  0.18571205328663534,\n",
       "  0.1889609792005339,\n",
       "  0.18350977460409457,\n",
       "  0.18414724243635699,\n",
       "  0.18192980481257298,\n",
       "  0.17973604488772463,\n",
       "  0.18068736370917043,\n",
       "  0.17956266754190625,\n",
       "  0.17922720131887088,\n",
       "  0.18119834183882444,\n",
       "  0.17667280709777919,\n",
       "  0.17835423467571948,\n",
       "  0.17693572727808557,\n",
       "  0.17680227367119564,\n",
       "  0.17440284291425118,\n",
       "  0.1776335538724389,\n",
       "  0.18059721345511767,\n",
       "  0.17501039291024781,\n",
       "  0.17821769497602613,\n",
       "  0.17872744758981216,\n",
       "  0.17967681458020104,\n",
       "  0.17839149217575023,\n",
       "  0.1782668643154314,\n",
       "  0.17753617793923968,\n",
       "  0.17396513508298458,\n",
       "  0.17563336090870829,\n",
       "  0.17673201491846502,\n",
       "  0.17524602925166105,\n",
       "  0.17865296629811986],\n",
       " 'val_acc': [0.53890000000000005,\n",
       "  0.65820000000000001,\n",
       "  0.64410000000000001,\n",
       "  0.73280000000000001,\n",
       "  0.7097,\n",
       "  0.71179999999999999,\n",
       "  0.74319999999999997,\n",
       "  0.75180000000000002,\n",
       "  0.72529999999999994,\n",
       "  0.78039999999999998,\n",
       "  0.76919999999999999,\n",
       "  0.79400000000000004,\n",
       "  0.78039999999999998,\n",
       "  0.77610000000000001,\n",
       "  0.80579999999999996,\n",
       "  0.82769999999999999,\n",
       "  0.80889999999999995,\n",
       "  0.76259999999999994,\n",
       "  0.82779999999999998,\n",
       "  0.79849999999999999,\n",
       "  0.8206,\n",
       "  0.84150000000000003,\n",
       "  0.81699999999999995,\n",
       "  0.81830000000000003,\n",
       "  0.80679999999999996,\n",
       "  0.8145,\n",
       "  0.8528,\n",
       "  0.84279999999999999,\n",
       "  0.8004,\n",
       "  0.84950000000000003,\n",
       "  0.81499999999999995,\n",
       "  0.84570000000000001,\n",
       "  0.83260000000000001,\n",
       "  0.86229999999999996,\n",
       "  0.84860000000000002,\n",
       "  0.85699999999999998,\n",
       "  0.86199999999999999,\n",
       "  0.84599999999999997,\n",
       "  0.83289999999999997,\n",
       "  0.81630000000000003,\n",
       "  0.84379999999999999,\n",
       "  0.83779999999999999,\n",
       "  0.82099999999999995,\n",
       "  0.84689999999999999,\n",
       "  0.83030000000000004,\n",
       "  0.88649999999999995,\n",
       "  0.87829999999999997,\n",
       "  0.87119999999999997,\n",
       "  0.87219999999999998,\n",
       "  0.87229999999999996,\n",
       "  0.86939999999999995,\n",
       "  0.88239999999999996,\n",
       "  0.874,\n",
       "  0.87780000000000002,\n",
       "  0.86209999999999998,\n",
       "  0.87070000000000003,\n",
       "  0.88060000000000005,\n",
       "  0.86419999999999997,\n",
       "  0.86860000000000004,\n",
       "  0.8669,\n",
       "  0.87350000000000005,\n",
       "  0.8831,\n",
       "  0.86899999999999999,\n",
       "  0.87690000000000001,\n",
       "  0.88439999999999996,\n",
       "  0.87639999999999996,\n",
       "  0.88480000000000003,\n",
       "  0.87509999999999999,\n",
       "  0.88770000000000004,\n",
       "  0.87,\n",
       "  0.88300000000000001,\n",
       "  0.85340000000000005,\n",
       "  0.88529999999999998,\n",
       "  0.87709999999999999,\n",
       "  0.88300000000000001,\n",
       "  0.87980000000000003,\n",
       "  0.87490000000000001,\n",
       "  0.87970000000000004,\n",
       "  0.88270000000000004,\n",
       "  0.86729999999999996,\n",
       "  0.87439999999999996,\n",
       "  0.88329999999999997,\n",
       "  0.88749999999999996,\n",
       "  0.87979999971389766,\n",
       "  0.87419999999999998,\n",
       "  0.88090000000000002,\n",
       "  0.87780000000000002,\n",
       "  0.87439999999999996,\n",
       "  0.87839999999999996,\n",
       "  0.88239999999999996,\n",
       "  0.88229999999999997,\n",
       "  0.88449999999999995,\n",
       "  0.87849999999999995,\n",
       "  0.88009999999999999,\n",
       "  0.88229999999999997,\n",
       "  0.88019999999999998,\n",
       "  0.87919999999999998,\n",
       "  0.88649999999999995,\n",
       "  0.88339999999999996,\n",
       "  0.88149999999999995,\n",
       "  0.88300000000000001,\n",
       "  0.88819999999999999,\n",
       "  0.88690000000000002,\n",
       "  0.88280000000000003,\n",
       "  0.88829999999999998,\n",
       "  0.88519999999999999,\n",
       "  0.8841,\n",
       "  0.8851,\n",
       "  0.88539999999999996,\n",
       "  0.88270000000000004,\n",
       "  0.88539999999999996,\n",
       "  0.8841,\n",
       "  0.88349999999999995,\n",
       "  0.88460000000000005,\n",
       "  0.8841,\n",
       "  0.88219999999999998,\n",
       "  0.8841,\n",
       "  0.88400000000000001,\n",
       "  0.88260000000000005,\n",
       "  0.88549999999999995,\n",
       "  0.88419999999999999,\n",
       "  0.8821,\n",
       "  0.88570000000000004,\n",
       "  0.88349999999999995,\n",
       "  0.88460000000000005],\n",
       " 'val_loss': [1.2710243595123292,\n",
       "  1.024442473602295,\n",
       "  1.219056301021576,\n",
       "  0.77984502239227294,\n",
       "  0.88859160881042476,\n",
       "  0.88536055831909177,\n",
       "  0.78866167736053472,\n",
       "  0.7821835824966431,\n",
       "  1.0464290390014648,\n",
       "  0.67788062200546262,\n",
       "  0.71316751661300659,\n",
       "  0.6177116805076599,\n",
       "  0.6985910892486572,\n",
       "  0.74070389566421513,\n",
       "  0.64855906486511228,\n",
       "  0.52513356523513799,\n",
       "  0.61782697010040288,\n",
       "  0.83913949918746944,\n",
       "  0.54026636075973511,\n",
       "  0.6708791100502014,\n",
       "  0.596183885383606,\n",
       "  0.48952425336837768,\n",
       "  0.61539171171188356,\n",
       "  0.61648050451278691,\n",
       "  0.66529784793853763,\n",
       "  0.62476552820205689,\n",
       "  0.46731398525238038,\n",
       "  0.51066169977188114,\n",
       "  0.78286873950958247,\n",
       "  0.48167811646461489,\n",
       "  0.64424070532321931,\n",
       "  0.51381728153228756,\n",
       "  0.59427632045745848,\n",
       "  0.44312653465270996,\n",
       "  0.52337587938308716,\n",
       "  0.46478630852699282,\n",
       "  0.45100304136276242,\n",
       "  0.53497074947357182,\n",
       "  0.60650951209068293,\n",
       "  0.67145477330684666,\n",
       "  0.55442093963623051,\n",
       "  0.61154360599517821,\n",
       "  0.7161600631713867,\n",
       "  0.53116617469787597,\n",
       "  0.59411686620712278,\n",
       "  0.3821934090614319,\n",
       "  0.42422818527221678,\n",
       "  0.45269980621337891,\n",
       "  0.4573889108657837,\n",
       "  0.46647667102813722,\n",
       "  0.4677189905166626,\n",
       "  0.42369017963409422,\n",
       "  0.45477120866775511,\n",
       "  0.44018694515228274,\n",
       "  0.528741089630127,\n",
       "  0.47617960090637207,\n",
       "  0.4287327440738678,\n",
       "  0.50569855508804318,\n",
       "  0.49448675832748412,\n",
       "  0.51524235372543337,\n",
       "  0.46855596060752869,\n",
       "  0.40798068504333496,\n",
       "  0.48309634380340577,\n",
       "  0.44404983024597167,\n",
       "  0.41979229917526245,\n",
       "  0.46825221238136294,\n",
       "  0.41188151731491091,\n",
       "  0.45604339647293091,\n",
       "  0.41572891960144043,\n",
       "  0.48570142641067504,\n",
       "  0.41874156150817871,\n",
       "  0.59868776917457578,\n",
       "  0.41873454766273499,\n",
       "  0.47521594820022584,\n",
       "  0.44673214964866637,\n",
       "  0.44819734508991244,\n",
       "  0.465086909532547,\n",
       "  0.45169281063079836,\n",
       "  0.43108127861022949,\n",
       "  0.49052591409683227,\n",
       "  0.4851108784198761,\n",
       "  0.4097193164348602,\n",
       "  0.40519193801879883,\n",
       "  0.44993425285816191,\n",
       "  0.47513687353134154,\n",
       "  0.44493855638504026,\n",
       "  0.45481850204467772,\n",
       "  0.47561444206237791,\n",
       "  0.45664310913085937,\n",
       "  0.44292299690246584,\n",
       "  0.4449633514404297,\n",
       "  0.43062407197952268,\n",
       "  0.4543004807472229,\n",
       "  0.4504941047668457,\n",
       "  0.44462568922042844,\n",
       "  0.45588943815231325,\n",
       "  0.46380598430633546,\n",
       "  0.42130651860237123,\n",
       "  0.43961210746765139,\n",
       "  0.44536118907928468,\n",
       "  0.43942606220245362,\n",
       "  0.42228011236190793,\n",
       "  0.42268328380584719,\n",
       "  0.44431229543685913,\n",
       "  0.42306924772262572,\n",
       "  0.43182802057266234,\n",
       "  0.44311844611167905,\n",
       "  0.43537815818786624,\n",
       "  0.4358757927894592,\n",
       "  0.44641589040756224,\n",
       "  0.43905351486206057,\n",
       "  0.44487456884384158,\n",
       "  0.44770963239669798,\n",
       "  0.44060039949417112,\n",
       "  0.44170599966049195,\n",
       "  0.45110984234809876,\n",
       "  0.44299496741294858,\n",
       "  0.44365681800842283,\n",
       "  0.44538546829223635,\n",
       "  0.43886156220436096,\n",
       "  0.44088044719696046,\n",
       "  0.45185869240760801,\n",
       "  0.43695342874526977,\n",
       "  0.4459655343532562,\n",
       "  0.44208942909240723]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(act):# SWISH - 125\n",
    "    init_shape = (3, 32, 32) if K.image_dim_ordering() == 'th' else (32, 32, 3)\n",
    "    # For WRN-16-8 put N = 2, k = 8\n",
    "    # For WRN-28-10 put N = 4, k = 10\n",
    "    # For WRN-40-4 put N = 6, k = 4\n",
    "    model = wrn.build_model(16, 4, init_shape, num_classes)\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Model Created\")\n",
    "    batch_size  = 128\n",
    "    epochs = 150\n",
    "\n",
    "    opt = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    lr_1 = keras.callbacks.LearningRateScheduler(schedule)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    print(\"Finished compiling\")\n",
    "\n",
    "    ####################\n",
    "    # Network training #\n",
    "    ####################\n",
    "\n",
    "    print(\"Gonna fit the model\")\n",
    "#     his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test), callbacks=[lr_1])\n",
    "#     print(his.history)\n",
    "    return his.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 1/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 1.5876 - acc: 0.4164 - val_loss: 1.7169 - val_acc: 0.4275\n",
      "Epoch 2/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 1.1048 - acc: 0.6065 - val_loss: 1.3743 - val_acc: 0.5580\n",
      "Epoch 3/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.8679 - acc: 0.6948 - val_loss: 0.9323 - val_acc: 0.6794\n",
      "Epoch 4/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.7192 - acc: 0.7482 - val_loss: 0.8433 - val_acc: 0.7124\n",
      "Epoch 5/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.6179 - acc: 0.7842 - val_loss: 0.6428 - val_acc: 0.7787\n",
      "Epoch 6/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.5489 - acc: 0.8103 - val_loss: 0.5743 - val_acc: 0.8018\n",
      "Epoch 7/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.4939 - acc: 0.8293 - val_loss: 0.5800 - val_acc: 0.8008\n",
      "Epoch 8/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.4509 - acc: 0.8422 - val_loss: 0.4698 - val_acc: 0.8412\n",
      "Epoch 9/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.4110 - acc: 0.8568 - val_loss: 0.6941 - val_acc: 0.7676\n",
      "Epoch 10/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.3863 - acc: 0.8646 - val_loss: 0.5822 - val_acc: 0.8031\n",
      "Epoch 11/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.3548 - acc: 0.8766 - val_loss: 0.5646 - val_acc: 0.8127\n",
      "Epoch 12/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.3318 - acc: 0.8844 - val_loss: 0.4546 - val_acc: 0.8493\n",
      "Epoch 13/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.3127 - acc: 0.8907 - val_loss: 0.4260 - val_acc: 0.8574\n",
      "Epoch 14/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.2961 - acc: 0.8957 - val_loss: 0.4369 - val_acc: 0.8592\n",
      "Epoch 15/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.2766 - acc: 0.9029 - val_loss: 0.5007 - val_acc: 0.8400\n",
      "Epoch 16/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.2572 - acc: 0.9095 - val_loss: 0.4962 - val_acc: 0.8462\n",
      "Epoch 17/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.2530 - acc: 0.9117 - val_loss: 0.4432 - val_acc: 0.8716\n",
      "Epoch 18/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.2292 - acc: 0.9200 - val_loss: 0.3442 - val_acc: 0.8852\n",
      "Epoch 19/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.2207 - acc: 0.9231 - val_loss: 0.4921 - val_acc: 0.8489\n",
      "Epoch 20/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.2069 - acc: 0.9271 - val_loss: 0.5167 - val_acc: 0.8519\n",
      "Epoch 21/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.1961 - acc: 0.9315 - val_loss: 0.4259 - val_acc: 0.8676\n",
      "Epoch 22/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.1869 - acc: 0.9340 - val_loss: 0.8235 - val_acc: 0.8027\n",
      "Epoch 23/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.1819 - acc: 0.9351 - val_loss: 0.4198 - val_acc: 0.8722\n",
      "Epoch 24/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.1681 - acc: 0.9410 - val_loss: 0.3681 - val_acc: 0.8914\n",
      "Epoch 25/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1671 - acc: 0.9412 - val_loss: 0.6312 - val_acc: 0.8404\n",
      "Epoch 26/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.1554 - acc: 0.9451 - val_loss: 0.3691 - val_acc: 0.8920\n",
      "Epoch 27/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1505 - acc: 0.9461 - val_loss: 0.3927 - val_acc: 0.8836\n",
      "Epoch 28/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1435 - acc: 0.9486 - val_loss: 0.3957 - val_acc: 0.8919\n",
      "Epoch 29/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1397 - acc: 0.9513 - val_loss: 0.3623 - val_acc: 0.8954\n",
      "Epoch 30/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.1300 - acc: 0.9540 - val_loss: 0.6251 - val_acc: 0.8411\n",
      "Epoch 31/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1249 - acc: 0.9566 - val_loss: 0.4725 - val_acc: 0.8731\n",
      "Epoch 32/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1208 - acc: 0.9574 - val_loss: 0.3419 - val_acc: 0.9021\n",
      "Epoch 33/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1153 - acc: 0.9588 - val_loss: 0.3585 - val_acc: 0.8987\n",
      "Epoch 34/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1101 - acc: 0.9606 - val_loss: 0.4963 - val_acc: 0.8717\n",
      "Epoch 35/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1017 - acc: 0.9624 - val_loss: 0.4172 - val_acc: 0.8889\n",
      "Epoch 36/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.1008 - acc: 0.9647 - val_loss: 0.3505 - val_acc: 0.9044\n",
      "Epoch 37/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0992 - acc: 0.9641 - val_loss: 0.4096 - val_acc: 0.8963\n",
      "Epoch 38/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0960 - acc: 0.9656 - val_loss: 0.3979 - val_acc: 0.8990\n",
      "Epoch 39/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0915 - acc: 0.9670 - val_loss: 0.4566 - val_acc: 0.8908\n",
      "Epoch 40/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0855 - acc: 0.9700 - val_loss: 0.4150 - val_acc: 0.8933\n",
      "Epoch 41/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0800 - acc: 0.9718 - val_loss: 0.3647 - val_acc: 0.9022\n",
      "Epoch 42/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0847 - acc: 0.9703 - val_loss: 0.4342 - val_acc: 0.8878\n",
      "Epoch 43/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0805 - acc: 0.9711 - val_loss: 0.3794 - val_acc: 0.9040\n",
      "Epoch 44/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0731 - acc: 0.9740 - val_loss: 0.4468 - val_acc: 0.8955\n",
      "Epoch 45/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0696 - acc: 0.9748 - val_loss: 0.3454 - val_acc: 0.9091\n",
      "Epoch 46/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0429 - acc: 0.9854 - val_loss: 0.2817 - val_acc: 0.9253\n",
      "Epoch 47/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0303 - acc: 0.9904 - val_loss: 0.2736 - val_acc: 0.9262\n",
      "Epoch 48/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0261 - acc: 0.9916 - val_loss: 0.2765 - val_acc: 0.9271\n",
      "Epoch 49/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.2826 - val_acc: 0.9286\n",
      "Epoch 50/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.2898 - val_acc: 0.9254\n",
      "Epoch 51/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0221 - acc: 0.9930 - val_loss: 0.2856 - val_acc: 0.9293\n",
      "Epoch 52/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0185 - acc: 0.9944 - val_loss: 0.2851 - val_acc: 0.9296\n",
      "Epoch 53/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.2875 - val_acc: 0.9292\n",
      "Epoch 54/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.2849 - val_acc: 0.9317\n",
      "Epoch 55/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.2879 - val_acc: 0.9311\n",
      "Epoch 56/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0149 - acc: 0.9958 - val_loss: 0.3019 - val_acc: 0.9293\n",
      "Epoch 57/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0163 - acc: 0.9949 - val_loss: 0.2910 - val_acc: 0.9279\n",
      "Epoch 58/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0155 - acc: 0.9949 - val_loss: 0.2951 - val_acc: 0.9310\n",
      "Epoch 59/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.3031 - val_acc: 0.9301\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0154 - acc: 0.9951 - val_loss: 0.2985 - val_acc: 0.9300\n",
      "Epoch 61/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0136 - acc: 0.9959 - val_loss: 0.2961 - val_acc: 0.9321\n",
      "Epoch 62/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.3121 - val_acc: 0.9289\n",
      "Epoch 63/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0149 - acc: 0.9954 - val_loss: 0.2988 - val_acc: 0.9310\n",
      "Epoch 64/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.3201 - val_acc: 0.9298\n",
      "Epoch 65/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.3149 - val_acc: 0.9300\n",
      "Epoch 66/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0129 - acc: 0.9960 - val_loss: 0.3051 - val_acc: 0.9320\n",
      "Epoch 67/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.3324 - val_acc: 0.9277\n",
      "Epoch 68/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0124 - acc: 0.9964 - val_loss: 0.3177 - val_acc: 0.9302\n",
      "Epoch 69/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.3169 - val_acc: 0.9298\n",
      "Epoch 70/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.3177 - val_acc: 0.9303\n",
      "Epoch 71/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.3171 - val_acc: 0.9305\n",
      "Epoch 72/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.3151 - val_acc: 0.9307\n",
      "Epoch 73/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.3200 - val_acc: 0.9299\n",
      "Epoch 74/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.3137 - val_acc: 0.9302\n",
      "Epoch 75/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0113 - acc: 0.9963 - val_loss: 0.3269 - val_acc: 0.9282\n",
      "Epoch 76/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.3384 - val_acc: 0.9276\n",
      "Epoch 77/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.3319 - val_acc: 0.9316\n",
      "Epoch 78/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.3329 - val_acc: 0.9296\n",
      "Epoch 79/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.3283 - val_acc: 0.9288\n",
      "Epoch 80/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.3462 - val_acc: 0.9274\n",
      "Epoch 81/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.3310 - val_acc: 0.9305\n",
      "Epoch 82/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.3247 - val_acc: 0.9325\n",
      "Epoch 83/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.3308 - val_acc: 0.9305\n",
      "Epoch 84/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.3369 - val_acc: 0.9286\n",
      "Epoch 85/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.3371 - val_acc: 0.9309\n",
      "Epoch 86/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.3319 - val_acc: 0.9314\n",
      "Epoch 87/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.3290 - val_acc: 0.9316\n",
      "Epoch 88/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.3280 - val_acc: 0.9300\n",
      "Epoch 89/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.3255 - val_acc: 0.9303\n",
      "Epoch 90/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.3244 - val_acc: 0.9320\n",
      "Epoch 91/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.3235 - val_acc: 0.9314\n",
      "Epoch 92/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.3259 - val_acc: 0.9318\n",
      "Epoch 93/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.3255 - val_acc: 0.93260.00 - ETA: 3s - loss: 0.\n",
      "Epoch 94/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.3260 - val_acc: 0.9322\n",
      "Epoch 95/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.3263 - val_acc: 0.9313\n",
      "Epoch 96/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.3251 - val_acc: 0.9322\n",
      "Epoch 97/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.3257 - val_acc: 0.9316\n",
      "Epoch 98/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.3255 - val_acc: 0.9322\n",
      "Epoch 99/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.3244 - val_acc: 0.9315\n",
      "Epoch 100/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.3237 - val_acc: 0.9324\n",
      "Epoch 101/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.3245 - val_acc: 0.9325\n",
      "Epoch 102/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.3266 - val_acc: 0.9315\n",
      "Epoch 103/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.3252 - val_acc: 0.9318\n",
      "Epoch 104/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.3262 - val_acc: 0.9320\n",
      "Epoch 105/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.3274 - val_acc: 0.9326\n",
      "Epoch 106/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.3279 - val_acc: 0.9322\n",
      "Epoch 107/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.3273 - val_acc: 0.9327\n",
      "Epoch 108/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.3271 - val_acc: 0.9322\n",
      "Epoch 109/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.3279 - val_acc: 0.9321\n",
      "Epoch 110/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.3270 - val_acc: 0.9321\n",
      "Epoch 111/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.3270 - val_acc: 0.9318\n",
      "Epoch 112/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.3275 - val_acc: 0.9326\n",
      "Epoch 113/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.3276 - val_acc: 0.9322\n",
      "Epoch 114/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.3271 - val_acc: 0.9321\n",
      "Epoch 115/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.3261 - val_acc: 0.9324\n",
      "Epoch 116/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.3261 - val_acc: 0.9322\n",
      "Epoch 117/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.3273 - val_acc: 0.9323\n",
      "Epoch 118/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.3274 - val_acc: 0.9328\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.3272 - val_acc: 0.9318\n",
      "Epoch 120/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.3263 - val_acc: 0.9320\n",
      "Epoch 121/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.3275 - val_acc: 0.9319\n",
      "Epoch 122/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.3276 - val_acc: 0.9322\n",
      "Epoch 123/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.3266 - val_acc: 0.9323\n",
      "Epoch 124/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.3269 - val_acc: 0.9320\n",
      "Epoch 125/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.3278 - val_acc: 0.9328\n",
      "Epoch 126/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.3278 - val_acc: 0.9325\n",
      "Epoch 127/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.3278 - val_acc: 0.9322\n",
      "Epoch 128/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.3277 - val_acc: 0.9325\n",
      "Epoch 129/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.3268 - val_acc: 0.9326\n",
      "Epoch 130/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.3278 - val_acc: 0.9323\n",
      "Epoch 131/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.3275 - val_acc: 0.9329\n",
      "Epoch 132/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.3265 - val_acc: 0.9321\n",
      "Epoch 133/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.3265 - val_acc: 0.9324\n",
      "Epoch 134/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.3269 - val_acc: 0.9318\n",
      "Epoch 135/150\n",
      "390/390 [==============================] - 84s 214ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.3272 - val_acc: 0.9319\n",
      "Epoch 136/150\n",
      "390/390 [==============================] - 83s 214ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.3264 - val_acc: 0.9320\n",
      "Epoch 137/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.3270 - val_acc: 0.9324\n",
      "Epoch 138/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.3263 - val_acc: 0.9318\n",
      "Epoch 139/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.3262 - val_acc: 0.9321\n",
      "Epoch 140/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.3254 - val_acc: 0.9322\n",
      "Epoch 141/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.3274 - val_acc: 0.9321\n",
      "Epoch 142/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.3279 - val_acc: 0.9321\n",
      "Epoch 143/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.3269 - val_acc: 0.9323\n",
      "Epoch 144/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.3264 - val_acc: 0.9322\n",
      "Epoch 145/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.3262 - val_acc: 0.9318\n",
      "Epoch 146/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.3265 - val_acc: 0.9321\n",
      "Epoch 147/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.3263 - val_acc: 0.9324\n",
      "Epoch 148/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.3260 - val_acc: 0.9320\n",
      "Epoch 149/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.3260 - val_acc: 0.9322\n",
      "Epoch 150/150\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.3269 - val_acc: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [0.41630574268219295,\n",
       "  0.60651267244145013,\n",
       "  0.69475858200808771,\n",
       "  0.74823548285518271,\n",
       "  0.78426772535784262,\n",
       "  0.81027430217542207,\n",
       "  0.82930301572024379,\n",
       "  0.84213586784074579,\n",
       "  0.8568334937822295,\n",
       "  0.86469361561783464,\n",
       "  0.87662415782495839,\n",
       "  0.88438402311825626,\n",
       "  0.89066008979171984,\n",
       "  0.89575312800769968,\n",
       "  0.90295155594507237,\n",
       "  0.9095484439975603,\n",
       "  0.91167388512685121,\n",
       "  0.92001523899274795,\n",
       "  0.92314324673070414,\n",
       "  0.92705325633622071,\n",
       "  0.93144449791466155,\n",
       "  0.93397096567212068,\n",
       "  0.93511389154327729,\n",
       "  0.94102903428963447,\n",
       "  0.94126965028565779,\n",
       "  0.94509945456554079,\n",
       "  0.94610202115508357,\n",
       "  0.94858838626884823,\n",
       "  0.95128205128205123,\n",
       "  0.95399807323686725,\n",
       "  0.95662897012537396,\n",
       "  0.957451074732241,\n",
       "  0.95885466798819674,\n",
       "  0.96067933906987191,\n",
       "  0.96242380497889291,\n",
       "  0.96466955407751187,\n",
       "  0.96410811675983166,\n",
       "  0.9655718639335229,\n",
       "  0.96697545720860101,\n",
       "  0.97006336222637302,\n",
       "  0.97178777668925098,\n",
       "  0.97028392683362064,\n",
       "  0.97108598007083435,\n",
       "  0.97397337179364474,\n",
       "  0.97479547643875675,\n",
       "  0.98542268210433404,\n",
       "  0.9903954122171289,\n",
       "  0.99163859480269489,\n",
       "  0.99195941606698446,\n",
       "  0.99330285532871498,\n",
       "  0.99300881410256414,\n",
       "  0.9944203597425878,\n",
       "  0.99458614051973049,\n",
       "  0.99473157051282046,\n",
       "  0.99419958253050733,\n",
       "  0.99584937441758248,\n",
       "  0.99488691049085665,\n",
       "  0.99490696184138738,\n",
       "  0.99538819379518917,\n",
       "  0.9950473211421238,\n",
       "  0.99589342948717952,\n",
       "  0.9959657996146436,\n",
       "  0.99542829640063868,\n",
       "  0.99588947708039932,\n",
       "  0.99532803980096396,\n",
       "  0.99596968238691053,\n",
       "  0.99599358974358976,\n",
       "  0.99640735390481849,\n",
       "  0.99606993906307495,\n",
       "  0.99637419871794874,\n",
       "  0.99626685934489401,\n",
       "  0.99703240297067841,\n",
       "  0.9972529675970484,\n",
       "  0.99673163298042988,\n",
       "  0.99625040102662821,\n",
       "  0.99701522435897438,\n",
       "  0.99650770714823522,\n",
       "  0.99667467948717947,\n",
       "  0.9973908156903033,\n",
       "  0.99735322429233531,\n",
       "  0.99701235162014756,\n",
       "  0.99691506410256414,\n",
       "  0.99717003855478636,\n",
       "  0.99667467948717947,\n",
       "  0.9967717356623691,\n",
       "  0.99704961466268616,\n",
       "  0.99797481552775102,\n",
       "  0.99731312159127361,\n",
       "  0.99773419956997267,\n",
       "  0.99793471286493418,\n",
       "  0.99801491819056787,\n",
       "  0.99749358357394935,\n",
       "  0.99783445620789224,\n",
       "  0.99847609881296118,\n",
       "  0.9978766025641026,\n",
       "  0.99737327558549893,\n",
       "  0.99769187540141302,\n",
       "  0.99813522617901829,\n",
       "  0.99817708333333333,\n",
       "  0.99823378293500475,\n",
       "  0.99807507218479308,\n",
       "  0.99781440487648376,\n",
       "  0.99795476419634266,\n",
       "  0.99789461020211745,\n",
       "  0.99789461020211745,\n",
       "  0.99853766025641022,\n",
       "  0.99825385358368812,\n",
       "  0.99853625280718639,\n",
       "  0.99795673076923075,\n",
       "  0.99825385358368812,\n",
       "  0.9983974358974359,\n",
       "  0.99785244062916167,\n",
       "  0.99823717948717949,\n",
       "  0.99827392421323058,\n",
       "  0.99805502085338471,\n",
       "  0.9981953801732435,\n",
       "  0.99825553418659119,\n",
       "  0.99811698717948716,\n",
       "  0.99839434810533079,\n",
       "  0.99811698717948716,\n",
       "  0.99823378291586384,\n",
       "  0.99825553416746871,\n",
       "  0.99841594481873597,\n",
       "  0.99807692307692308,\n",
       "  0.99783236994219648,\n",
       "  0.99823548285518271,\n",
       "  0.99825553416746871,\n",
       "  0.99837740384615381,\n",
       "  0.99843448940269752,\n",
       "  0.99821543150465186,\n",
       "  0.99773637820512817,\n",
       "  0.99785244059087985,\n",
       "  0.99829563683028555,\n",
       "  0.99809512351620144,\n",
       "  0.99819711538461542,\n",
       "  0.99807321774553781,\n",
       "  0.99829727564102566,\n",
       "  0.99829399486191395,\n",
       "  0.9983958934873276,\n",
       "  0.99835579082451076,\n",
       "  0.99823717948717949,\n",
       "  0.99813522617901829,\n",
       "  0.9985749839626219,\n",
       "  0.99801491819056787,\n",
       "  0.99785657051282051,\n",
       "  0.99855491331393853,\n",
       "  0.99805502085338471,\n",
       "  0.99821543150465186,\n",
       "  0.99829563683028555,\n",
       "  0.99813701923076925],\n",
       " 'loss': [1.5878574134525596,\n",
       "  1.1046203077699956,\n",
       "  0.86788108506032891,\n",
       "  0.71920611531756651,\n",
       "  0.61782838516522953,\n",
       "  0.54899408543266692,\n",
       "  0.49400700686602855,\n",
       "  0.45091805711058724,\n",
       "  0.41091036435155714,\n",
       "  0.38607821668766229,\n",
       "  0.35476039276889476,\n",
       "  0.33195241231603961,\n",
       "  0.31274721411737755,\n",
       "  0.29605898206571296,\n",
       "  0.27656819253806164,\n",
       "  0.25710936293680009,\n",
       "  0.2530365376794495,\n",
       "  0.22915608509251578,\n",
       "  0.22073968279273762,\n",
       "  0.20689403652226959,\n",
       "  0.1961225794032479,\n",
       "  0.18696630893607991,\n",
       "  0.18193791802395295,\n",
       "  0.16803900442388833,\n",
       "  0.16699238880192349,\n",
       "  0.155404543320663,\n",
       "  0.15047864957730817,\n",
       "  0.14342267874880482,\n",
       "  0.13974685844702597,\n",
       "  0.12985646414618962,\n",
       "  0.12496762043884024,\n",
       "  0.12083574633759721,\n",
       "  0.11522512308557636,\n",
       "  0.10998032122305429,\n",
       "  0.10177299863024518,\n",
       "  0.10089158759663645,\n",
       "  0.099180079312958622,\n",
       "  0.096078292510621929,\n",
       "  0.091541963908193885,\n",
       "  0.085450268980685737,\n",
       "  0.079949735612738465,\n",
       "  0.084666980165757549,\n",
       "  0.080463631057685711,\n",
       "  0.073060859301876557,\n",
       "  0.069585689031278472,\n",
       "  0.042917693421641409,\n",
       "  0.030308313931902899,\n",
       "  0.026146314063258552,\n",
       "  0.025207675877512745,\n",
       "  0.021333893580570754,\n",
       "  0.022119126898141054,\n",
       "  0.018430111513460534,\n",
       "  0.018061119834194783,\n",
       "  0.017800645123964225,\n",
       "  0.017783929219717064,\n",
       "  0.014894075002395785,\n",
       "  0.016266187023398947,\n",
       "  0.015471837205772297,\n",
       "  0.015310549250731283,\n",
       "  0.015434762288780119,\n",
       "  0.013565765960643498,\n",
       "  0.01340086039363729,\n",
       "  0.014756793471786468,\n",
       "  0.014111257188696203,\n",
       "  0.014561826264008253,\n",
       "  0.01295924800402405,\n",
       "  0.012621456070785195,\n",
       "  0.012411584898945501,\n",
       "  0.012264326244967944,\n",
       "  0.011832097564370205,\n",
       "  0.011677783822094065,\n",
       "  0.010380331810652245,\n",
       "  0.0099695503598459748,\n",
       "  0.010379467347746175,\n",
       "  0.011339970282316304,\n",
       "  0.010634614832890339,\n",
       "  0.010974838237867941,\n",
       "  0.010446313942800491,\n",
       "  0.0088123724760811283,\n",
       "  0.0093244028184772069,\n",
       "  0.0093666580871684564,\n",
       "  0.0095758269229778443,\n",
       "  0.0089150462247247052,\n",
       "  0.0099396838920746133,\n",
       "  0.010159293855942324,\n",
       "  0.0088748627403743841,\n",
       "  0.0069193997719756281,\n",
       "  0.0084234591487052334,\n",
       "  0.0078236771679346204,\n",
       "  0.0072706390856766704,\n",
       "  0.0067417947518680198,\n",
       "  0.0079814260973414906,\n",
       "  0.007001362341924615,\n",
       "  0.0056857417117165479,\n",
       "  0.007157425526663876,\n",
       "  0.007878532864148604,\n",
       "  0.0073570860530367613,\n",
       "  0.0065151061176988399,\n",
       "  0.0063562209629125371,\n",
       "  0.0062744191644332559,\n",
       "  0.0063796870356361704,\n",
       "  0.0067469560981402157,\n",
       "  0.0072013754825644679,\n",
       "  0.0066770605610269439,\n",
       "  0.0071124161682991002,\n",
       "  0.0053441047024814625,\n",
       "  0.0057576447069758877,\n",
       "  0.005782083795251451,\n",
       "  0.0062050859312129877,\n",
       "  0.0066330827321461235,\n",
       "  0.0062675979163032023,\n",
       "  0.0068476320384638521,\n",
       "  0.0060975836105614852,\n",
       "  0.0062488287185003544,\n",
       "  0.0063806714881169688,\n",
       "  0.0059634892943250667,\n",
       "  0.0060875875525622314,\n",
       "  0.0060826542183535937,\n",
       "  0.0057479486319900186,\n",
       "  0.0063573113782928346,\n",
       "  0.006421038497827933,\n",
       "  0.0058858863747791338,\n",
       "  0.00540224454015491,\n",
       "  0.0063624425089353906,\n",
       "  0.0068352288986282877,\n",
       "  0.005720229279805652,\n",
       "  0.0059659839638027505,\n",
       "  0.0055577497636803835,\n",
       "  0.0058733500124466135,\n",
       "  0.006305849751319233,\n",
       "  0.006773734138009903,\n",
       "  0.0066717235566168907,\n",
       "  0.0059040703325668924,\n",
       "  0.0063672963396341617,\n",
       "  0.0063402206839945838,\n",
       "  0.0062347605889370005,\n",
       "  0.0063938099632744128,\n",
       "  0.0059094262420329611,\n",
       "  0.006058175457956106,\n",
       "  0.0058663398322323923,\n",
       "  0.0059108963615681909,\n",
       "  0.0060699599871458527,\n",
       "  0.0053549603572609975,\n",
       "  0.006614808423839328,\n",
       "  0.0063788847936591944,\n",
       "  0.0050086921326039681,\n",
       "  0.0061286125495479482,\n",
       "  0.0058153001227041713,\n",
       "  0.0054872959303494239,\n",
       "  0.0062743481125485581],\n",
       " 'val_acc': [0.42749999999999999,\n",
       "  0.55800000000000005,\n",
       "  0.6794,\n",
       "  0.71240000000000003,\n",
       "  0.77869999999999995,\n",
       "  0.80179999999999996,\n",
       "  0.80079999999999996,\n",
       "  0.84119999999999995,\n",
       "  0.76759999999999995,\n",
       "  0.80310000000000004,\n",
       "  0.81269999999999998,\n",
       "  0.84930000000000005,\n",
       "  0.85740000000000005,\n",
       "  0.85919999999999996,\n",
       "  0.83999999999999997,\n",
       "  0.84619999999999995,\n",
       "  0.87160000000000004,\n",
       "  0.88519999999999999,\n",
       "  0.84889999999999999,\n",
       "  0.85189999999999999,\n",
       "  0.86760000000000004,\n",
       "  0.80269999999999997,\n",
       "  0.87219999999999998,\n",
       "  0.89139999999999997,\n",
       "  0.84040000000000004,\n",
       "  0.89200000000000002,\n",
       "  0.88360000000000005,\n",
       "  0.89190000000000003,\n",
       "  0.89539999999999997,\n",
       "  0.84109999999999996,\n",
       "  0.87309999999999999,\n",
       "  0.90210000000000001,\n",
       "  0.89870000000000005,\n",
       "  0.87170000000000003,\n",
       "  0.88890000000000002,\n",
       "  0.90439999999999998,\n",
       "  0.89629999999999999,\n",
       "  0.89900000000000002,\n",
       "  0.89080000000000004,\n",
       "  0.89329999999999998,\n",
       "  0.9022,\n",
       "  0.88780000000000003,\n",
       "  0.90400000000000003,\n",
       "  0.89549999999999996,\n",
       "  0.90910000000000002,\n",
       "  0.92530000000000001,\n",
       "  0.92620000000000002,\n",
       "  0.92710000000000004,\n",
       "  0.92859999999999998,\n",
       "  0.9254,\n",
       "  0.92930000000000001,\n",
       "  0.92959999999999998,\n",
       "  0.92920000000000003,\n",
       "  0.93169999999999997,\n",
       "  0.93110000000000004,\n",
       "  0.92930000000000001,\n",
       "  0.92789999999999995,\n",
       "  0.93100000000000005,\n",
       "  0.93010000000000004,\n",
       "  0.93000000000000005,\n",
       "  0.93210000000000004,\n",
       "  0.92889999999999995,\n",
       "  0.93100000000000005,\n",
       "  0.92979999999999996,\n",
       "  0.93000000000000005,\n",
       "  0.93200000000000005,\n",
       "  0.92769999999999997,\n",
       "  0.93020000000000003,\n",
       "  0.92979999999999996,\n",
       "  0.93030000000000002,\n",
       "  0.93049999999999999,\n",
       "  0.93069999999999997,\n",
       "  0.92989999999999995,\n",
       "  0.93020000000000003,\n",
       "  0.92820000000000003,\n",
       "  0.92759999999999998,\n",
       "  0.93159999999999998,\n",
       "  0.92959999999999998,\n",
       "  0.92879999999999996,\n",
       "  0.9274,\n",
       "  0.93049999999999999,\n",
       "  0.9325,\n",
       "  0.93049999999999999,\n",
       "  0.92859999999999998,\n",
       "  0.93089999999999995,\n",
       "  0.93140000000000001,\n",
       "  0.93159999999999998,\n",
       "  0.93000000000000005,\n",
       "  0.93030000000000002,\n",
       "  0.93200000000000005,\n",
       "  0.93140000000000001,\n",
       "  0.93179999999999996,\n",
       "  0.93259999999999998,\n",
       "  0.93220000000000003,\n",
       "  0.93130000000000002,\n",
       "  0.93220000000000003,\n",
       "  0.93159999999999998,\n",
       "  0.93220000000000003,\n",
       "  0.93149999999999999,\n",
       "  0.93240000000000001,\n",
       "  0.9325,\n",
       "  0.93149999999999999,\n",
       "  0.93179999999999996,\n",
       "  0.93200000000000005,\n",
       "  0.93259999999999998,\n",
       "  0.93220000000000003,\n",
       "  0.93269999999999997,\n",
       "  0.93220000000000003,\n",
       "  0.93210000000000004,\n",
       "  0.93210000000000004,\n",
       "  0.93179999999999996,\n",
       "  0.93259999999999998,\n",
       "  0.93220000000000003,\n",
       "  0.93210000000000004,\n",
       "  0.93240000152587887,\n",
       "  0.93220000000000003,\n",
       "  0.93230000000000002,\n",
       "  0.93279999999999996,\n",
       "  0.93179999999999996,\n",
       "  0.93200000000000005,\n",
       "  0.93189999999999995,\n",
       "  0.93220000000000003,\n",
       "  0.93230000000000002,\n",
       "  0.93200000000000005,\n",
       "  0.93279999999999996,\n",
       "  0.9325,\n",
       "  0.93220000000000003,\n",
       "  0.9325,\n",
       "  0.93259999999999998,\n",
       "  0.93230000000000002,\n",
       "  0.93289999999999995,\n",
       "  0.93210000000000004,\n",
       "  0.93240000000000001,\n",
       "  0.93179999999999996,\n",
       "  0.93189999999999995,\n",
       "  0.93200000000000005,\n",
       "  0.93240000000000001,\n",
       "  0.93179999999999996,\n",
       "  0.93210000000000004,\n",
       "  0.93220000000000003,\n",
       "  0.93210000000000004,\n",
       "  0.93210000000000004,\n",
       "  0.93230000000000002,\n",
       "  0.93220000000000003,\n",
       "  0.93179999999999996,\n",
       "  0.93210000000000004,\n",
       "  0.93240000000000001,\n",
       "  0.93200000000000005,\n",
       "  0.93220000000000003,\n",
       "  0.93240000000000001],\n",
       " 'val_loss': [1.7168946941375733,\n",
       "  1.3742601840972901,\n",
       "  0.93227429618835445,\n",
       "  0.84331794042587283,\n",
       "  0.64278037695884704,\n",
       "  0.57432736549377439,\n",
       "  0.57999803194999699,\n",
       "  0.46977667989730837,\n",
       "  0.69412958567142491,\n",
       "  0.58222676663398742,\n",
       "  0.56464111700057984,\n",
       "  0.45456848335266115,\n",
       "  0.42603105611801145,\n",
       "  0.43690005235671997,\n",
       "  0.50069644851684569,\n",
       "  0.49618645248413085,\n",
       "  0.44315238494873049,\n",
       "  0.34422427916526793,\n",
       "  0.49210006351470947,\n",
       "  0.51668885238170625,\n",
       "  0.4258785704612732,\n",
       "  0.82352846016883852,\n",
       "  0.41980796756744387,\n",
       "  0.36812101697921751,\n",
       "  0.63119109666347506,\n",
       "  0.36908114356994631,\n",
       "  0.39265749378204345,\n",
       "  0.39568018059730531,\n",
       "  0.3622884970188141,\n",
       "  0.62513647767901426,\n",
       "  0.47254780826568604,\n",
       "  0.34190111244916915,\n",
       "  0.35845414004325865,\n",
       "  0.49633987152576448,\n",
       "  0.41721706361770627,\n",
       "  0.35047458066940307,\n",
       "  0.40956838645935056,\n",
       "  0.39787706918716431,\n",
       "  0.45659670181274414,\n",
       "  0.41498505764007571,\n",
       "  0.36465478255748751,\n",
       "  0.43420578342378141,\n",
       "  0.37943905949592588,\n",
       "  0.44679811312407253,\n",
       "  0.34539203970432281,\n",
       "  0.28166014761924746,\n",
       "  0.27363970355987549,\n",
       "  0.27652324759960173,\n",
       "  0.28258590369224551,\n",
       "  0.28978198008537293,\n",
       "  0.28564639885425569,\n",
       "  0.28508682172298433,\n",
       "  0.28753927085399628,\n",
       "  0.28492268899679185,\n",
       "  0.28791579409837725,\n",
       "  0.30193009991645814,\n",
       "  0.29097592504024505,\n",
       "  0.29509745352268218,\n",
       "  0.30308650145530702,\n",
       "  0.29848175077438355,\n",
       "  0.29614632213115694,\n",
       "  0.31208607051372528,\n",
       "  0.29878436019420623,\n",
       "  0.32006974343061445,\n",
       "  0.31493295516967773,\n",
       "  0.30513684761524201,\n",
       "  0.33238100016117095,\n",
       "  0.31770595312118532,\n",
       "  0.31690624816417695,\n",
       "  0.31765802872180937,\n",
       "  0.31706219773292543,\n",
       "  0.31514596808552742,\n",
       "  0.31997460327148436,\n",
       "  0.31366422953605649,\n",
       "  0.32689222505092619,\n",
       "  0.33839743235111236,\n",
       "  0.33191470801830292,\n",
       "  0.3328973644256592,\n",
       "  0.32832193417549133,\n",
       "  0.34619320404529569,\n",
       "  0.33095267982482912,\n",
       "  0.32474470863342286,\n",
       "  0.3307954493522644,\n",
       "  0.33685790221691131,\n",
       "  0.33707563166618348,\n",
       "  0.33186796021461484,\n",
       "  0.32898042275905609,\n",
       "  0.32799979567527771,\n",
       "  0.3255476164340973,\n",
       "  0.32435694665908815,\n",
       "  0.32351831338405607,\n",
       "  0.32587593116760255,\n",
       "  0.32549579615592955,\n",
       "  0.32601084330081942,\n",
       "  0.32631855852603914,\n",
       "  0.32505167009830477,\n",
       "  0.32567907285690306,\n",
       "  0.32552086100578309,\n",
       "  0.32439614162445068,\n",
       "  0.32374145846366881,\n",
       "  0.3244614089488983,\n",
       "  0.32662760989665984,\n",
       "  0.32521197085380554,\n",
       "  0.32615865330696103,\n",
       "  0.32740272965431211,\n",
       "  0.32786250004768369,\n",
       "  0.32729980077743531,\n",
       "  0.32707363772392273,\n",
       "  0.32788505594730377,\n",
       "  0.32704112663269042,\n",
       "  0.32704800620079039,\n",
       "  0.32747921786308287,\n",
       "  0.32762928414344789,\n",
       "  0.32707825407981872,\n",
       "  0.32608381684124471,\n",
       "  0.32608397283554075,\n",
       "  0.32734346454143526,\n",
       "  0.32735418148040774,\n",
       "  0.3271743685245514,\n",
       "  0.32632108039855956,\n",
       "  0.32745459203720095,\n",
       "  0.32759048168659211,\n",
       "  0.32664380135536192,\n",
       "  0.32692776103019716,\n",
       "  0.32779620883464811,\n",
       "  0.32778534409999849,\n",
       "  0.32782883470058444,\n",
       "  0.32771572165489199,\n",
       "  0.32681918907165525,\n",
       "  0.32778359305858612,\n",
       "  0.32749332423210142,\n",
       "  0.32650164179801938,\n",
       "  0.32651130664348604,\n",
       "  0.32691677784919737,\n",
       "  0.32717469792366027,\n",
       "  0.32642932262420654,\n",
       "  0.32695652611255643,\n",
       "  0.32630554909706116,\n",
       "  0.32615230619907382,\n",
       "  0.32544301631450651,\n",
       "  0.32744472146034242,\n",
       "  0.32791603326797486,\n",
       "  0.32685281372070313,\n",
       "  0.32639099063873289,\n",
       "  0.3262358028650284,\n",
       "  0.32646659579277038,\n",
       "  0.3262822607755661,\n",
       "  0.32601168701648714,\n",
       "  0.32601012248992922,\n",
       "  0.32691902470588685]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
